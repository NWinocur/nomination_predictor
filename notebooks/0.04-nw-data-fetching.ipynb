{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching: FJC and Congress.gov API\n",
    "\n",
    "This notebook is responsible for fetching and initially processing data from our primary sources:\n",
    "\n",
    "1. Federal Judicial Center (FJC) CSV and Excel files\n",
    "2. Congress.gov API judicial nomination data\n",
    "\n",
    "According to the project architecture, this notebook will:\n",
    "1. Download or use cached data from the FJC and Congress.gov API\n",
    "2. Perform minimal transformations to convert to dataframes\n",
    "3. Save the resulting dataframes to `data/raw` for further processing by downstream notebooks\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from nomination_predictor.config import (EXTERNAL_DATA_DIR, INTERIM_DATA_DIR,\n",
    "                                         PROCESSED_DATA_DIR, RAW_DATA_DIR)\n",
    "from nomination_predictor.congress_api import CongressAPIClient\n",
    "from nomination_predictor.fjc_data import (FJC_DATA_DIR, build_seat_timeline,\n",
    "                                           get_predecessor_info, load_fjc_csv,\n",
    "                                           load_judges_data)\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Federal Judicial Center (FJC) Data\n",
    "\n",
    "The FJC data is our canonical source for judicial seat timelines, judge demographics, and nomination failures.\n",
    "\n",
    "### Check if FJC data exists or download if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All required FJC data files found in /home/wsl2ubuntuuser/nomination_predictor/data/external/FederalJudicialCenter\n",
      "  ✓ Optional file found: judges.xlsx\n",
      "  ✓ Optional file found: categories.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Check if the FJC data directory exists and contains expected files\n",
    "required_files = [\n",
    "    'judges.csv',\n",
    "    'demographics.csv',\n",
    "    'federal-judicial-service.csv',\n",
    "    'education.csv',\n",
    "    'professional-career.csv',\n",
    "    'other-nominations-recess.csv'\n",
    "]\n",
    "\n",
    "\n",
    "# Optional files\n",
    "optional_files = [\n",
    "    'judges.xlsx',\n",
    "    'categories.xlsx',\n",
    "]\n",
    "# Check required files\n",
    "missing_files = []\n",
    "for file in required_files:\n",
    "    if not (FJC_DATA_DIR / file).exists():\n",
    "        missing_files.append(file)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"⚠️ Missing required FJC data files: {missing_files}\")\n",
    "    print(\"Please download the FJC data files from the Federal Judicial Center website and place them in:\")\n",
    "    print(f\"  {FJC_DATA_DIR}\")\n",
    "    print(\"\\nDownload links:\")\n",
    "    print(\"  (all from https://www.fjc.gov/history/judges/biographical-directory-article-iii-federal-judges-export)\")\n",
    "    print(\"  - https://www.fjc.gov/sites/default/files/history/judges.xlsx\")\n",
    "    print(\"  - https://www.fjc.gov/sites/default/files/history/judges.csv\")\n",
    "    print(\"  - https://www.fjc.gov/sites/default/files/history/categories.xlsx\")\n",
    "    print(\"  - https://www.fjc.gov/sites/default/files/history/demographics.csv\")\n",
    "    print(\"  - https://www.fjc.gov/sites/default/files/history/federal-judicial-service.csv\")\n",
    "    print(\"  - https://www.fjc.gov/sites/default/files/history/education.csv\")\n",
    "    print(\"  - https://www.fjc.gov/sites/default/files/history/professional-career.csv\")\n",
    "    print(\"  - https://www.fjc.gov/sites/default/files/history/other-nominations-recess.csv\")\n",
    "else:\n",
    "    print(f\"✓ All required FJC data files found in {FJC_DATA_DIR}\")\n",
    "    \n",
    "    # Check optional files\n",
    "    for file in optional_files:\n",
    "        if (FJC_DATA_DIR / file).exists():\n",
    "            print(f\"  ✓ Optional file found: {file}\")\n",
    "        else:\n",
    "            print(f\"  ℹ️ Optional file not found: {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FJC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-11 15:10:28\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: federal-judicial-service.csv\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded service data: 4720 records\n"
     ]
    }
   ],
   "source": [
    "# Load the service data\n",
    "try:\n",
    "    service_df = load_fjc_csv('federal-judicial-service.csv')\n",
    "    print(f\"Loaded service data: {len(service_df)} records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: federal-judicial-service.csv not found\")\n",
    "    service_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-11 15:10:40\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_judges_data\u001b[0m - \u001b[1mLoading judges data\u001b[0m\n",
      "\u001b[32m2025-07-11 15:10:40\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: judges.csv\u001b[0m\n",
      "\u001b[32m2025-07-11 15:10:51\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: demographics.csv\u001b[0m\n",
      "\u001b[32m2025-07-11 15:10:51\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_judges_data\u001b[0m - \u001b[1mAdded demographic information to judges data\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded judges data: 4022 records\n"
     ]
    }
   ],
   "source": [
    "# Load judges data with demographics\n",
    "try:\n",
    "    judges_df = load_judges_data(include_demographics=True)\n",
    "    print(f\"Loaded judges data: {len(judges_df)} records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: judges.csv not found\")\n",
    "    judges_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Seat Timeline (Master Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-11 15:10:51\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[1mBuilding seat timeline table\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['seat_id', 'court', 'commission_date', 'termination_date', 'termination_reason'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Build the seat timeline if we have service data\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service_df.empty:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     seat_timeline_df = \u001b[43mbuild_seat_timeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBuilt seat timeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(seat_timeline_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Preview the seat timeline\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nomination_predictor/nomination_predictor/fjc_data.py:120\u001b[39m, in \u001b[36mbuild_seat_timeline\u001b[39m\u001b[34m(service_df)\u001b[39m\n\u001b[32m    117\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mBuilding seat timeline table\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Select and rename relevant columns\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m seat_timeline = \u001b[43mservice_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseat_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcourt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m                           \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcommission_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtermination_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m                           \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtermination_reason\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# Sort by seat_id and commission_date\u001b[39;00m\n\u001b[32m    125\u001b[39m seat_timeline = seat_timeline.sort_values([\u001b[33m'\u001b[39m\u001b[33mseat_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcommission_date\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['seat_id', 'court', 'commission_date', 'termination_date', 'termination_reason'] not in index\""
     ]
    }
   ],
   "source": [
    "# Build the seat timeline if we have service data\n",
    "if not service_df.empty:\n",
    "    seat_timeline_df = build_seat_timeline(service_df)\n",
    "    print(f\"Built seat timeline: {len(seat_timeline_df)} records\")\n",
    "    \n",
    "    # Preview the seat timeline\n",
    "    seat_timeline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predecessor lookup table\n",
    "if 'seat_timeline_df' in locals():\n",
    "    predecessor_lookup = get_predecessor_info(seat_timeline_df)\n",
    "    print(f\"Created predecessor lookup: {len(predecessor_lookup)} records\")\n",
    "    \n",
    "    # Preview the predecessor lookup\n",
    "    predecessor_lookup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Congress.gov API Data\n",
    "\n",
    "The Congress.gov API provides detailed information about judicial nominations, including:\n",
    "- Nomination date\n",
    "- Nominee information\n",
    "- Confirmation status and date\n",
    "- Committee actions\n",
    "\n",
    "### Setup API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if API key is available\n",
    "api_key = os.environ.get(\"CONGRESS_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"❌ Error: CONGRESS_API_KEY environment variable not set\")\n",
    "    print(\"Please set the CONGRESS_API_KEY environment variable to your Congress.gov API key\")\n",
    "    print(\"You can request an API key at: https://api.congress.gov/sign-up/\")\n",
    "else:\n",
    "    print(\"✓ Congress API key found in environment variables\")\n",
    "    # Initialize the API client\n",
    "    congress_client = CongressAPIClient(api_key)\n",
    "    print(\"✓ Congress API client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Judicial Nominations from Recent Congresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch judicial nominations from recent congresses\n",
    "# Congress numbering: 116th (2019-2021), 117th (2021-2023), 118th (2023-2025)\n",
    "\n",
    "if 'congress_client' in locals():\n",
    "    congresses = [118, 117, 116]  # Most recent three congresses\n",
    "    all_nominations = []\n",
    "    \n",
    "    for congress in congresses:\n",
    "        try:\n",
    "            print(f\"Fetching judicial nominations for the {congress}th Congress...\")\n",
    "            nominations = congress_client.get_judicial_nominations(congress)\n",
    "            print(f\"  ✓ Retrieved {len(nominations)} judicial nominations\")\n",
    "            all_nominations.extend(nominations)\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error fetching nominations for {congress}th Congress: {str(e)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    nominations_df = pd.DataFrame(all_nominations)\n",
    "    print(f\"\\nTotal nominations retrieved: {len(nominations_df)}\")\n",
    "    \n",
    "    # Preview the nominations\n",
    "    if not nominations_df.empty:\n",
    "        nominations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crosswalk and Join Data Sources\n",
    "\n",
    "Now we'll crosswalk the Congress.gov nomination data to the FJC seat timeline using the nomination-to-seat matching logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.fjc_data import crosswalk_congress_api\n",
    "\n",
    "# Crosswalk if we have both datasets\n",
    "if 'nominations_df' in locals() and 'seat_timeline_df' in locals() and 'judges_df' in locals():\n",
    "    crosswalked_df = crosswalk_congress_api(\n",
    "        nominations_df,\n",
    "        seat_timeline_df,\n",
    "        judges_df\n",
    "    )\n",
    "    \n",
    "    print(f\"Crosswalked nominations: {len(crosswalked_df)} records\")\n",
    "    print(f\"Match statistics:\\n{crosswalked_df['seat_match_method'].value_counts()}\")\n",
    "    \n",
    "    # Preview crosswalked data\n",
    "    crosswalked_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Master Dataset\n",
    "\n",
    "Now we'll create the master dataset by joining the seat timeline with the crosswalked nominations data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.fjc_data import create_master_dataset\n",
    "\n",
    "# Create master dataset if we have both datasets\n",
    "if 'seat_timeline_df' in locals() and 'crosswalked_df' in locals():\n",
    "    master_df = create_master_dataset(\n",
    "        seat_timeline_df,\n",
    "        crosswalked_df\n",
    "    )\n",
    "    \n",
    "    print(f\"Created master dataset: {len(master_df)} records\")\n",
    "    \n",
    "    # Preview master dataset\n",
    "    master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Data to Raw Directory\n",
    "\n",
    "Save the datasets to the raw data directory for use by downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save seat timeline\n",
    "if 'seat_timeline_df' in locals() and not seat_timeline_df.empty:\n",
    "    output_path = RAW_DATA_DIR / \"seat_timeline.csv\"\n",
    "    seat_timeline_df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved seat timeline to {output_path}\")\n",
    "\n",
    "# Save crosswalked nominations\n",
    "if 'crosswalked_df' in locals() and not crosswalked_df.empty:\n",
    "    output_path = RAW_DATA_DIR / \"crosswalked_nominations.csv\"\n",
    "    crosswalked_df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved crosswalked nominations to {output_path}\")\n",
    "    \n",
    "# Save master dataset\n",
    "if 'master_df' in locals() and not master_df.empty:\n",
    "    output_path = RAW_DATA_DIR / \"master_dataset.csv\"\n",
    "    master_df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved master dataset to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded Federal Judicial Center (FJC) data, the canonical source for judicial seats and judges\n",
    "2. Built the seat timeline as our master table\n",
    "3. Fetched judicial nominations from the Congress.gov API\n",
    "4. Crosswalked the nomination data to FJC seat IDs\n",
    "5. Created a master dataset joining these sources\n",
    "6. Saved all datasets to the raw data directory for further processing by downstream notebooks\n",
    "\n",
    "The next notebook (1.00-nw-data-cleaning-feature-creation.ipynb) will load these datasets, clean them, and engineer features for modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
