{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching: FJC and Congress.gov API\n",
    "\n",
    "This notebook is responsible for fetching and initially processing data from our primary sources:\n",
    "\n",
    "1. Federal Judicial Center (FJC) CSV and Excel files\n",
    "2. Congress.gov API judicial nomination data\n",
    "\n",
    "According to the project architecture, this notebook will:\n",
    "1. Download or use cached data from the FJC and Congress.gov API\n",
    "2. Perform minimal transformations to convert to dataframes\n",
    "3. Save the resulting dataframes to `data/raw` for further processing by downstream notebooks\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from nomination_predictor.congress_api import CongressAPIClient\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Federal Judicial Center (FJC) Data\n",
    "\n",
    "The FJC data is our canonical source for judicial seat timelines, judge demographics, and nomination failures.\n",
    "\n",
    "### Check if FJC data exists or download if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if required FJC data files exist and download any missing ones\n",
    "from nomination_predictor.config import EXTERNAL_DATA_DIR\n",
    "from nomination_predictor.fjc_data import (REQUIRED_FJC_FILES,\n",
    "                                           ensure_fjc_data_files,\n",
    "                                           load_fjc_data)\n",
    "\n",
    "# Check for missing files and download them if needed\n",
    "downloaded, failed = ensure_fjc_data_files()\n",
    "\n",
    "# Report status\n",
    "if downloaded:\n",
    "    print(f\"✓ Downloaded {len(downloaded)} previously missing files: {', '.join(downloaded)}\")\n",
    "if failed:\n",
    "    print(f\"❌ Failed to download {len(failed)} files: {', '.join(failed)}\")\n",
    "    \n",
    "# Also report on which files are present\n",
    "present_files = [f for f in REQUIRED_FJC_FILES if (EXTERNAL_DATA_DIR / f).exists()]\n",
    "if len(present_files) == len(REQUIRED_FJC_FILES):\n",
    "    print(f\"✓ All required FJC data files are available in {EXTERNAL_DATA_DIR}\")\n",
    "else:\n",
    "    missing = set(REQUIRED_FJC_FILES) - set(present_files)\n",
    "    print(f\"⚠️ Still missing {len(missing)} required files: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FJC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all FJC data files (with auto-download enabled by default)\n",
    "fjc_data = load_fjc_data()\n",
    "\n",
    "# Access individual DataFrames\n",
    "print(f\"Loaded FJC data files:\")\n",
    "for key, df in fjc_data.items():\n",
    "    print(f\"- {key}: {len(df)} records\")\n",
    "\n",
    "# Store references to commonly used DataFrames for easier access\n",
    "judges_df = fjc_data.get('judges')\n",
    "demographics_df = fjc_data.get('demographics')\n",
    "education_df = fjc_data.get('education')\n",
    "federal_judicial_service_df = fjc_data.get('federal_judicial_service')\n",
    "other_nominations_recess_df = fjc_data.get('other_nominations_recess')\n",
    "other_federal_judicial_service_df = fjc_data.get('other_federal_judicial_service')\n",
    "professional_career_df = fjc_data.get('professional_career')\n",
    "\n",
    "# Create a dictionary of all FJC dataframes for easy iteration\n",
    "all_dataframes = {\n",
    "    'judges': judges_df,\n",
    "    'demographics': demographics_df,\n",
    "    'education': education_df,\n",
    "    'federal_judicial_service': federal_judicial_service_df,\n",
    "    'other_nominations_recess': other_nominations_recess_df,\n",
    "    'other_federal_judicial_service': other_federal_judicial_service_df,\n",
    "    'professional_career': professional_career_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a \"seat timeline\" inferred from FJC's data about when judges were in service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.dataset import build_and_validate_seat_timeline\n",
    "\n",
    "try:\n",
    "    seat_timeline_df = build_and_validate_seat_timeline(federal_judicial_service_df)\n",
    "    print(f\"✅ Successfully built seat timeline with {len(seat_timeline_df):,} records\")\n",
    "    all_dataframes['seat_timeline'] = seat_timeline_df\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Congress.gov API Data\n",
    "\n",
    "The Congress.gov API provides detailed information about judicial nominations, including:\n",
    "- Nomination date\n",
    "- Nominee information\n",
    "- Confirmation status and date\n",
    "- Committee actions\n",
    "\n",
    "### Setup API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if API key is available\n",
    "api_key = os.environ.get(\"CONGRESS_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"❌ Error: CONGRESS_API_KEY environment variable not set\")\n",
    "    print(\"Please set the CONGRESS_API_KEY environment variable to your Congress.gov API key\")\n",
    "    print(\"You can request an API key at: https://api.congress.gov/sign-up/\")\n",
    "else:\n",
    "    print(\"✓ Congress API key found in environment variables\")\n",
    "    # Initialize the API client\n",
    "    congress_client = CongressAPIClient(api_key)\n",
    "    print(\"✓ Congress API client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Judicial Nominations from Recent Congresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch judicial nominations from recent congresses\n",
    "# Congress numbering: 116th (2019-2021), 117th (2021-2023), 118th (2023-2025)\n",
    "# Import the new function\n",
    "import os\n",
    "\n",
    "from nomination_predictor.config import RAW_DATA_DIR\n",
    "from nomination_predictor.dataset import fetch_judicial_nominations\n",
    "\n",
    "# Define constants \n",
    "MOST_RECENT_CONGRESS_TERM_TO_GET = 120\n",
    "OLDEST_CONGRESS_TERM_TO_GET = 95\n",
    "\n",
    "# Define cache file path for nominations\n",
    "nominations_cache_file = os.path.join(RAW_DATA_DIR, \"nominations.csv\")\n",
    "\n",
    "# Fetch nominations with improved error handling\n",
    "nominations_df, success = fetch_judicial_nominations(\n",
    "    congress_client=congress_client,\n",
    "    most_recent_congress=MOST_RECENT_CONGRESS_TERM_TO_GET,\n",
    "    oldest_congress=OLDEST_CONGRESS_TERM_TO_GET,\n",
    "    auto_paginate=True,\n",
    "    cache_file=nominations_cache_file\n",
    ")\n",
    "\n",
    "# Critical validation - prevent proceeding if we don't have valid data\n",
    "if not success or len(nominations_df) == 0:\n",
    "    raise RuntimeError(\n",
    "        \"Failed to retrieve valid nomination data. \"\n",
    "        \"Please check the logs for errors and fix any issues before continuing.\"\n",
    "    )\n",
    "\n",
    "# Add to all_dataframes collection if we have valid data\n",
    "all_dataframes['nominations'] = nominations_df\n",
    "\n",
    "print(f\"✓ Successfully loaded {len(nominations_df)} nomination records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the nominations\n",
    "print(nominations_df.head())\n",
    "all_dataframes['nominations'] = nominations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch nominees for just-retrieved nominations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.dataset import \\\n",
    "    extract_nominee_urls_from_nominations_df\n",
    "\n",
    "# Extract nominee URLs from the JSON-structured nominations DataFrame\n",
    "nominee_urls_df = extract_nominee_urls_from_nominations_df(nominations_df)\n",
    "nominee_urls = nominee_urls_df['nominee_url'].tolist()\n",
    "print(f\"Found {len(nominee_urls)} nominations to retrieve nominee URLs for\")\n",
    "\n",
    "# nominee_urls_df is neither intended nor necessary to be saved as a file;\n",
    "# it's simply a utility for another API-driven retrieval operation below.\n",
    "# Each row contains: citation, nominee_url, congress, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.dataset import get_retrieval_date_range_message\n",
    "\n",
    "nominees_cache_file = os.path.join(RAW_DATA_DIR, \"nominees.csv\")\n",
    "\n",
    "# Check if we have cached data\n",
    "if os.path.exists(nominees_cache_file):\n",
    "    print(f\"Found cached nominees data at {nominees_cache_file}.  \")\n",
    "    nominees_df = pd.read_csv(nominees_cache_file)\n",
    "    print(f\"{get_retrieval_date_range_message(nominees_df, 'nominees')}\")\n",
    "elif 0 == len(nominee_urls):\n",
    "    print(\"⚠️ No nominee URLs found to download from\")\n",
    "else:\n",
    "    print(f\"Fetching nominee data for {len(nominee_urls)} nominations...\")\n",
    "\n",
    "    # Filter out records without nominee_url\n",
    "    nominees_data = congress_client.get_all_nominees_data(nominee_urls)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    nominees_df = pd.DataFrame(nominees_data)\n",
    "    print(f\"\\nTotal nominees retrieved: {len(nominees_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the nominees\n",
    "print(nominees_df.head())\n",
    "all_dataframes['nominees'] = nominees_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confirm \"nid\" and \"citation\" uniqueness to later use as FJC and Congress indexes, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for uniqueness in ID fields before saving to the raw data folder\n",
    "from nomination_predictor.dataset import validate_dataframe_ids\n",
    "\n",
    "print(\"Checking ID uniqueness in dataframes before saving...\")\n",
    "\n",
    "uniqueness_results = validate_dataframe_ids(all_dataframes) # discovered not all dataframes treat nid as unique due to re-appointments, position changes, etc.\n",
    "\n",
    "# Check if any dataframes have duplicate IDs\n",
    "problematic_dfs = [name for name, result in uniqueness_results.items() \n",
    "                   if not result.get('is_unique', True)]\n",
    "\n",
    "# if you want an easily-intuitive reason why a dataframe may not be able to use nid uniquely, try adding \"education\" to the \"uniqueness required\" list iterated through below, and see what it outputs.\n",
    "# you'll find numerous judges who are listed multiple times for having gotten different college or university degrees over the years.\n",
    "if any(name in [\"judges\", \"demographics\", \"nominations\", \"nominees\",] for name in problematic_dfs):\n",
    "    logger.warning(f\"⚠️ Found non-unique IDs in: {', '.join(problematic_dfs)}\")\n",
    "    for df_name in problematic_dfs:\n",
    "        result = uniqueness_results[df_name]\n",
    "        logger.warning(f\"\\nDuplicates in {df_name}:\")\n",
    "        display(result['duplicate_rows'])\n",
    "else:\n",
    "    \n",
    "    logger.info(\"✓ All ID fields are unique across unique-ID-required dataframes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Data to Raw Directory\n",
    "\n",
    "Save the datasets to the raw data directory for use by downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to the raw data directory\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from nomination_predictor.config import RAW_DATA_DIR\n",
    "\n",
    "# Create the raw data directory if it doesn't exist\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Add a timestamp for the manifest\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Save each FJC dataframe\n",
    "# Save all dataframes to the raw data directory\n",
    "print(f\"Saving dataframes to {RAW_DATA_DIR}...\")\n",
    "saved_files = []\n",
    "\n",
    "# Ensure the output directory exists\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save all dataframes from the all_dataframes collection\n",
    "for name, df in all_dataframes.items():\n",
    "    if df is not None and not df.empty:\n",
    "        try:\n",
    "            # Create filename\n",
    "            output_file = RAW_DATA_DIR / f\"{name}.csv\"\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(output_file, index=False)\n",
    "            saved_files.append(f\"{name}.csv\")\n",
    "            print(f\"  ✓ Saved {len(df):,} records to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error saving {name}: {str(e)}\")\n",
    "\n",
    "# Print summary\n",
    "if saved_files:\n",
    "    print(f\"\\n✅ Successfully saved {len(saved_files)} dataframes to {RAW_DATA_DIR}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No dataframes were saved - check if all_dataframes is populated correctly\")\n",
    "\n",
    "# Create a manifest file to track what was saved and when\n",
    "manifest_content = f\"\"\"# FJC Data Processing Manifest\n",
    "Processed on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "Note: Only column names are normalized (lowercase with underscores), data values remain unchanged\n",
    "Files saved:\n",
    "{chr(10).join(['- ' + file for file in saved_files])}\n",
    "\"\"\"\n",
    "\n",
    "with open(RAW_DATA_DIR / f\"fjc_data_manifest_{timestamp}.txt\", \"w\") as f:\n",
    "    f.write(manifest_content)\n",
    "\n",
    "print(f\"✓ Saved {len(saved_files)} files to {RAW_DATA_DIR}\")\n",
    "print(f\"✓ Created manifest: fjc_data_manifest_{timestamp}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Congress API retrieved nominations to cache file\n",
    "if nominations_df is not None and not nominations_df.empty:\n",
    "    # Ensure directory exists\n",
    "    os.makedirs(os.path.dirname(nominations_cache_file), exist_ok=True)\n",
    "    print(f\"Saving nominations to cache file: {nominations_cache_file}\")\n",
    "    nominations_df.to_csv(nominations_cache_file, index=False)\n",
    "    print(f\"✓ Saved {len(nominations_df)} nominations to cache\")\n",
    "    \n",
    "if nominees_df is not None and not nominees_df.empty:\n",
    "    # Ensure directory exists\n",
    "    os.makedirs(os.path.dirname(nominees_cache_file), exist_ok=True)\n",
    "    print(f\"Saving nominees to cache file: {nominees_cache_file}\")\n",
    "    nominees_df.to_csv(nominees_cache_file, index=False)\n",
    "    print(f\"✓ Saved {len(nominees_df)} nominees to cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded Federal Judicial Center (FJC) data, the canonical source for judicial seats and judges\n",
    "2. Built a raw seat timeline dataframe inferred from the FJC service data\n",
    "3. Fetched judicial nominations from the Congress.gov API\n",
    "4. Fetched judicial nominee data from the Congress.gov API\n",
    "5. Saved all datasets to the raw data directory for further processing by downstream notebooks\n",
    "\n",
    "The next notebook (e.g. 1.##-nw-feature-engineering.ipynb) will load these datasets, clean them, and engineer features for modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
