{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching: FJC and Congress.gov API\n",
    "\n",
    "This notebook is responsible for fetching and initially processing data from our primary sources:\n",
    "\n",
    "1. Federal Judicial Center (FJC) CSV and Excel files\n",
    "2. Congress.gov API judicial nomination data\n",
    "\n",
    "According to the project architecture, this notebook will:\n",
    "1. Download or use cached data from the FJC and Congress.gov API\n",
    "2. Perform minimal transformations to convert to dataframes\n",
    "3. Save the resulting dataframes to `data/raw` for further processing by downstream notebooks\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from nomination_predictor.congress_api import CongressAPIClient\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Federal Judicial Center (FJC) Data\n",
    "\n",
    "The FJC data is our canonical source for judicial seat timelines, judge demographics, and nomination failures.\n",
    "\n",
    "### Check if FJC data exists or download if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mensure_fjc_data_files\u001b[0m - \u001b[1mEnsuring FJC data files are available\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All required FJC data files are available in /home/wsl2ubuntuuser/nomination_predictor/data/external\n"
     ]
    }
   ],
   "source": [
    "# Check if required FJC data files exist and download any missing ones\n",
    "from nomination_predictor.config import EXTERNAL_DATA_DIR\n",
    "from nomination_predictor.fjc_data import (REQUIRED_FJC_FILES,\n",
    "                                           ensure_fjc_data_files,\n",
    "                                           load_fjc_data)\n",
    "\n",
    "# Check for missing files and download them if needed\n",
    "downloaded, failed = ensure_fjc_data_files()\n",
    "\n",
    "# Report status\n",
    "if downloaded:\n",
    "    print(f\"✓ Downloaded {len(downloaded)} previously missing files: {', '.join(downloaded)}\")\n",
    "if failed:\n",
    "    print(f\"❌ Failed to download {len(failed)} files: {', '.join(failed)}\")\n",
    "    \n",
    "# Also report on which files are present\n",
    "present_files = [f for f in REQUIRED_FJC_FILES if (EXTERNAL_DATA_DIR / f).exists()]\n",
    "if len(present_files) == len(REQUIRED_FJC_FILES):\n",
    "    print(f\"✓ All required FJC data files are available in {EXTERNAL_DATA_DIR}\")\n",
    "else:\n",
    "    missing = set(REQUIRED_FJC_FILES) - set(present_files)\n",
    "    print(f\"⚠️ Still missing {len(missing)} required files: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FJC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_data\u001b[0m - \u001b[1mLoading FJC data files\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mensure_fjc_data_files\u001b[0m - \u001b[1mEnsuring FJC data files are available\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: demographics.csv\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_data\u001b[0m - \u001b[1mLoaded demographics data with 4022 records\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: education.csv\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_data\u001b[0m - \u001b[1mLoaded education data with 8040 records\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: federal-judicial-service.csv\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_data\u001b[0m - \u001b[1mLoaded federal_judicial_service data with 4720 records\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: judges.csv\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_data\u001b[0m - \u001b[1mLoaded judges data with 4022 records\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: other-nominations-recess.csv\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_data\u001b[0m - \u001b[1mLoaded other_nominations_recess data with 828 records\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: other-federal-judicial-service.csv\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_data\u001b[0m - \u001b[1mLoaded other_federal_judicial_service data with 611 records\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_csv\u001b[0m - \u001b[1mLoading FJC data file: professional-career.csv\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_fjc_data\u001b[0m - \u001b[1mLoaded professional_career data with 19003 records\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FJC data files:\n",
      "- demographics: 4022 records\n",
      "- education: 8040 records\n",
      "- federal_judicial_service: 4720 records\n",
      "- judges: 4022 records\n",
      "- other_nominations_recess: 828 records\n",
      "- other_federal_judicial_service: 611 records\n",
      "- professional_career: 19003 records\n"
     ]
    }
   ],
   "source": [
    "# Load all FJC data files (with auto-download enabled by default)\n",
    "fjc_data = load_fjc_data()\n",
    "\n",
    "# Access individual DataFrames\n",
    "print(f\"Loaded FJC data files:\")\n",
    "for key, df in fjc_data.items():\n",
    "    print(f\"- {key}: {len(df)} records\")\n",
    "\n",
    "# Store references to commonly used DataFrames for easier access\n",
    "judges_df = fjc_data.get('judges')\n",
    "demographics_df = fjc_data.get('demographics')\n",
    "education_df = fjc_data.get('education')\n",
    "federal_judicial_service_df = fjc_data.get('federal_judicial_service')\n",
    "other_nominations_recess_df = fjc_data.get('other_nominations_recess')\n",
    "other_federal_judicial_service_df = fjc_data.get('other_federal_judicial_service')\n",
    "professional_career_df = fjc_data.get('professional_career')\n",
    "\n",
    "# Create a dictionary of all FJC dataframes for easy iteration\n",
    "all_dataframes = {\n",
    "    'judges': judges_df,\n",
    "    'demographics': demographics_df,\n",
    "    'education': education_df,\n",
    "    'federal_judicial_service': federal_judicial_service_df,\n",
    "    'other_nominations_recess': other_nominations_recess_df,\n",
    "    'other_federal_judicial_service': other_federal_judicial_service_df,\n",
    "    'professional_career': professional_career_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a \"seat timeline\" inferred from FJC's data about when judges were in service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[1mBuilding seat timeline table\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CA11SR: 1998-06-07 > 1981-10-01\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CA11SR: 1993-11-11 > 1981-10-01\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CA11SR: 2001-11-15 > 1981-10-01\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CA11SR: 1982-10-27 > 1981-10-01\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:42\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CA11SR: 1987-08-22 > 1981-10-01\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:43\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CACDSR: 1974-03-09 > 1966-09-18\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:43\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CAFCSR: 1986-04-14 > 1982-10-01\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:43\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CAFCSR: 2007-10-28 > 1982-10-01\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:43\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mbuild_seat_timeline\u001b[0m - \u001b[33m\u001b[1mEditing a derived vacancy_date: Termination date > successor commission for seat CAFCSR: 1989-08-09 > 1982-10-01\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:45\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mbuild_and_validate_seat_timeline\u001b[0m - \u001b[1mSuccessfully built seat timeline with 4,720 records\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully built seat timeline with 4,720 records\n"
     ]
    }
   ],
   "source": [
    "from nomination_predictor.dataset import build_and_validate_seat_timeline\n",
    "\n",
    "try:\n",
    "    seat_timeline_df = build_and_validate_seat_timeline(federal_judicial_service_df)\n",
    "    print(f\"✅ Successfully built seat timeline with {len(seat_timeline_df):,} records\")\n",
    "    all_dataframes['seat_timeline'] = seat_timeline_df\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Congress.gov API Data\n",
    "\n",
    "The Congress.gov API provides detailed information about judicial nominations, including:\n",
    "- Nomination date\n",
    "- Nominee information\n",
    "- Confirmation status and date\n",
    "- Committee actions\n",
    "\n",
    "### Setup API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Congress API key found in environment variables\n",
      "✓ Congress API client initialized\n"
     ]
    }
   ],
   "source": [
    "# Check if API key is available\n",
    "api_key = os.environ.get(\"CONGRESS_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"❌ Error: CONGRESS_API_KEY environment variable not set\")\n",
    "    print(\"Please set the CONGRESS_API_KEY environment variable to your Congress.gov API key\")\n",
    "    print(\"You can request an API key at: https://api.congress.gov/sign-up/\")\n",
    "else:\n",
    "    print(\"✓ Congress API key found in environment variables\")\n",
    "    # Initialize the API client\n",
    "    congress_client = CongressAPIClient(api_key)\n",
    "    print(\"✓ Congress API client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Judicial Nominations from Recent Congresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 18:24:45\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m<module>\u001b[0m - \u001b[1mFound cached nominations data at /home/wsl2ubuntuuser/nomination_predictor/data/raw/nominations.csv\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:45\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m<module>\u001b[0m - \u001b[1mLoaded 80 nominations from cache; see dataframe's retrieval_date column to check when this data was fetched\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Fetch judicial nominations from recent congresses\n",
    "# Congress numbering: 116th (2019-2021), 117th (2021-2023), 118th (2023-2025)\n",
    "import os\n",
    "from lzma import MODE_FAST\n",
    "from pathlib import Path\n",
    "\n",
    "from nomination_predictor.config import RAW_DATA_DIR\n",
    "\n",
    "MOST_RECENT_CONGRESS_TERM_TO_GET = 118\n",
    "OLDEST_CONGRESS_TERM_TO_GET = 118#90\n",
    "\n",
    "# Define cache file path for nominations\n",
    "nominations_cache_file = os.path.join(RAW_DATA_DIR, \"nominations.csv\")\n",
    "congresses = range(MOST_RECENT_CONGRESS_TERM_TO_GET, OLDEST_CONGRESS_TERM_TO_GET-1, -1)\n",
    "\n",
    "# Check if we have cached data\n",
    "if os.path.exists(nominations_cache_file):\n",
    "    logger.info(f\"Found cached nominations data at {nominations_cache_file}\")\n",
    "    nominations_df = pd.read_csv(nominations_cache_file, parse_dates=['receiveddate', 'authoritydate'])\n",
    "    logger.info(f\"Loaded {len(nominations_df)} nominations from cache; see dataframe's retrieval_date column to check when this data was fetched\")\n",
    "else:\n",
    "    # If no cache, fetch from API\n",
    "    all_nominations = []\n",
    "    \n",
    "    for congress in congresses:\n",
    "        try:\n",
    "            logger.info(f\"Fetching judicial nominations for the {congress}th Congress...\")\n",
    "            nominations = congress_client.get_judicial_nominations(congress, auto_paginate=False) # can choose to disable auto-pagination if you want less data, but faster, for development\n",
    "            logger.info(f\"  ✓ Retrieved {len(nominations)} judicial nominations\")\n",
    "            all_nominations.extend(nominations)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"  ❌ Error fetching nominations for {congress}th Congress: {str(e)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    nominations_df = pd.DataFrame(all_nominations)\n",
    "    logger.info(f\"\\nTotal nominations retrieved: {len(nominations_df)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             actions authoritydate citation  \\\n",
      "0  {'count': 6, 'url': 'https://api.congress.gov/...    2025-05-12   PN2012   \n",
      "1  {'count': 6, 'url': 'https://api.congress.gov/...    2025-05-12   PN2013   \n",
      "2  {'count': 6, 'url': 'https://api.congress.gov/...    2025-03-28    PN814   \n",
      "3  {'count': 11, 'url': 'https://api.congress.gov...    2025-03-28    PN771   \n",
      "4  {'count': 12, 'url': 'https://api.congress.gov...    2025-03-28    PN769   \n",
      "\n",
      "                                          committees  congress  \\\n",
      "0  {'count': 1, 'url': 'https://api.congress.gov/...       118   \n",
      "1  {'count': 1, 'url': 'https://api.congress.gov/...       118   \n",
      "2  {'count': 1, 'url': 'https://api.congress.gov/...       118   \n",
      "3  {'count': 1, 'url': 'https://api.congress.gov/...       118   \n",
      "4  {'count': 1, 'url': 'https://api.congress.gov/...       118   \n",
      "\n",
      "                                         description  \\\n",
      "0  James Graham Lake, of the District of Columbia...   \n",
      "1  Nicholas George Miranda, of the District of Co...   \n",
      "2  Lisa W. Wang, of the District of Columbia, to ...   \n",
      "3  Brandon S. Long, of Louisiana, to be United St...   \n",
      "4  Jerry Edwards, Jr., of Louisiana, to be United...   \n",
      "\n",
      "                                            hearings  \\\n",
      "0  {'count': 1, 'url': 'https://api.congress.gov/...   \n",
      "1  {'count': 1, 'url': 'https://api.congress.gov/...   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                        latestaction        nominationtype  \\\n",
      "0  {'actionDate': '2025-01-03', 'text': 'Returned...  {'isCivilian': True}   \n",
      "1  {'actionDate': '2025-01-03', 'text': 'Returned...  {'isCivilian': True}   \n",
      "2  {'actionDate': '2024-01-03', 'text': 'Returned...  {'isCivilian': True}   \n",
      "3  {'actionDate': '2023-12-14', 'text': 'Confirme...  {'isCivilian': True}   \n",
      "4  {'actionDate': '2023-12-14', 'text': 'Confirme...  {'isCivilian': True}   \n",
      "\n",
      "   number  ...  nominee_nomineecount nominee_ordinal nominee_organization  \\\n",
      "0    2012  ...                     1               1        The Judiciary   \n",
      "1    2013  ...                     1               1        The Judiciary   \n",
      "2     814  ...                     1               1        The Judiciary   \n",
      "3     771  ...                     1               1        The Judiciary   \n",
      "4     769  ...                     1               1        The Judiciary   \n",
      "\n",
      "                               nominee_positiontitle  \\\n",
      "0  Associate Judge of the Superior Court of the D...   \n",
      "1  Associate Judge of the Superior Court of the D...   \n",
      "2  Judge of the United States Court of Internatio...   \n",
      "3  United States District Judge for the Eastern D...   \n",
      "4  United States District Judge for the Western D...   \n",
      "\n",
      "                                         nominee_url       data_source  \\\n",
      "0  https://api.congress.gov/v3/nomination/118/201...  congress.gov_api   \n",
      "1  https://api.congress.gov/v3/nomination/118/201...  congress.gov_api   \n",
      "2  https://api.congress.gov/v3/nomination/118/814...  congress.gov_api   \n",
      "3  https://api.congress.gov/v3/nomination/118/771...  congress.gov_api   \n",
      "4  https://api.congress.gov/v3/nomination/118/769...  congress.gov_api   \n",
      "\n",
      "               retrieval_date is_detail_record executivecalendarnumber  \\\n",
      "0  2025-07-12T16:46:54.059538             True                     NaN   \n",
      "1  2025-07-12T16:46:54.612667             True                     NaN   \n",
      "2  2025-07-12T16:46:55.110622             True                     NaN   \n",
      "3  2025-07-12T16:46:55.625548             True                     NaN   \n",
      "4  2025-07-12T16:46:56.122202             True                     NaN   \n",
      "\n",
      "  isprivileged  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preview the nominations\n",
    "print(nominations_df.head())\n",
    "all_dataframes['nominations'] = nominations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch nominees for just-retrieved nominations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached nominees data at /home/wsl2ubuntuuser/nomination_predictor/data/raw/nominees.csv\n",
      "Loaded 80 nominee records from cache\n"
     ]
    }
   ],
   "source": [
    "nominees_cache_file = os.path.join(RAW_DATA_DIR, \"nominees.csv\")\n",
    "\n",
    "# Check if we have cached data\n",
    "if os.path.exists(nominees_cache_file):\n",
    "    print(f\"Found cached nominees data at {nominees_cache_file}\")\n",
    "    nominees_df = pd.read_csv(nominees_cache_file)\n",
    "    print(f\"Loaded {len(nominees_df)} nominee records from cache\")\n",
    "elif 'nominee_url' not in nominations_df.columns:\n",
    "    print(\"⚠️ No nominee_url column found in nominations_df\")\n",
    "else:\n",
    "    print(f\"Fetching nominee data for {len(nominations_df)} nominations...\")\n",
    "\n",
    "    # Filter out records without nominee_url\n",
    "    valid_nominations = nominations_df[~nominations_df['nominee_url'].isna()]\n",
    "    print(f\"Found {len(valid_nominations)} nominations with valid nominee_url\")\n",
    "\n",
    "    # Fetch nominee data for all nominations\n",
    "    nominees_data = congress_client.get_all_nominees_data(valid_nominations)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    nominees_df = pd.DataFrame(nominees_data)\n",
    "    print(f\"\\nTotal nominees retrieved: {len(nominees_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  firstName lastName middleName  ordinal state  congress  number  \\\n",
      "0     James     Lake     Graham        1    DC       118    2012   \n",
      "1  Nicholas  Miranda     George        1    DC       118    2013   \n",
      "2      Lisa     Wang         W.        1    DC       118     814   \n",
      "3   Brandon     Long         S.        1    LA       118     771   \n",
      "4     Jerry  Edwards        NaN        1    LA       118     769   \n",
      "\n",
      "                                         nominee_url citation  nominee_id  \\\n",
      "0  https://api.congress.gov/v3/nomination/118/201...   PN2012  118-2012-1   \n",
      "1  https://api.congress.gov/v3/nomination/118/201...   PN2013  118-2013-1   \n",
      "2  https://api.congress.gov/v3/nomination/118/814...    PN814   118-814-1   \n",
      "3  https://api.congress.gov/v3/nomination/118/771...    PN771   118-771-1   \n",
      "4  https://api.congress.gov/v3/nomination/118/769...    PN769   118-769-1   \n",
      "\n",
      "                data_source              retrieval_date suffix  \n",
      "0  congress.gov_api_nominee  2025-07-12T16:47:35.972746    NaN  \n",
      "1  congress.gov_api_nominee  2025-07-12T16:47:36.467999    NaN  \n",
      "2  congress.gov_api_nominee  2025-07-12T16:47:36.978530    NaN  \n",
      "3  congress.gov_api_nominee  2025-07-12T16:47:37.473676    NaN  \n",
      "4  congress.gov_api_nominee  2025-07-12T16:47:37.992605    Jr.  \n"
     ]
    }
   ],
   "source": [
    "# Preview the nominees\n",
    "print(nominees_df.head())\n",
    "all_dataframes['nominees'] = nominees_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: determine whether safe to move this to other notebook, or if other code already depends on it happening this early\n",
    "## Normalize column names, leaving data values as-is\n",
    "#nominees_df.columns = [col.casefold().replace(' ', '_') for col in nominees_df.columns]\n",
    "#print(\"\\nNominees DataFrame columns:\")\n",
    "#for col in sorted(nominees_df.columns):\n",
    "#     print(f\"- {col}: {nominees_df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confirm \"nid\" and \"citation\" uniqueness to later use as FJC and Congress indexes, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'nid' uniqueness for dataframe 'judges'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ID uniqueness in dataframes before saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[1mAll nid values are unique\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'nid' uniqueness for dataframe 'demographics'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[1mAll nid values are unique\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'nid' uniqueness for dataframe 'education'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m3350 duplicate nid values found\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1386811: appears 5 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1382346: appears 5 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1385901: appears 5 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1377081: appears 5 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1386451: appears 5 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  ... and 3345 more duplicate values\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'nid' uniqueness for dataframe 'federal_judicial_service'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m576 duplicate nid values found\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1390296: appears 6 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1381666: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1378736: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1385401: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1385551: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  ... and 571 more duplicate values\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'nid' uniqueness for dataframe 'other_nominations_recess'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m92 duplicate nid values found\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1378126: appears 7 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1391841: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1386321: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1392521: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1382066: appears 3 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  ... and 87 more duplicate values\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'nid' uniqueness for dataframe 'other_federal_judicial_service'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m62 duplicate nid values found\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1377121: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1392091: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1379716: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1378016: appears 3 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1393651: appears 3 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  ... and 57 more duplicate values\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'nid' uniqueness for dataframe 'professional_career'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m3852 duplicate nid values found\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  13761909: appears 23 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1389246: appears 18 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  13761366: appears 17 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1380021: appears 16 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1380601: appears 16 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  ... and 3847 more duplicate values\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'nid' uniqueness for dataframe 'seat_timeline'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m576 duplicate nid values found\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1390296: appears 6 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1384186: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1385551: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1378736: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  1382066: appears 4 times\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[33m\u001b[1mWARNING\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[33m\u001b[1m  ... and 571 more duplicate values\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'citation' uniqueness for dataframe 'nominations'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[1mAll citation values are unique\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mvalidate_dataframe_ids\u001b[0m - \u001b[1mChecking 'citation' uniqueness for dataframe 'nominees'\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mcheck_id_uniqueness\u001b[0m - \u001b[1mAll citation values are unique\u001b[0m\n",
      "\u001b[32m2025-07-12 18:24:46\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36m<module>\u001b[0m - \u001b[1m✓ All ID fields are unique across unique-ID-required dataframes.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check for uniqueness in ID fields before saving to the raw data folder\n",
    "from nomination_predictor.dataset import validate_dataframe_ids\n",
    "\n",
    "print(\"Checking ID uniqueness in dataframes before saving...\")\n",
    "\n",
    "uniqueness_results = validate_dataframe_ids(all_dataframes) # discovered not all dataframes treat nid as unique due to re-appointments, position changes, etc.\n",
    "\n",
    "# Check if any dataframes have duplicate IDs\n",
    "problematic_dfs = [name for name, result in uniqueness_results.items() \n",
    "                   if not result.get('is_unique', True)]\n",
    "\n",
    "# if you want an easily-intuitive reason why a dataframe may not be able to use nid uniquely, try adding \"education\" to the \"uniqueness required\" list iterated through below, and see what it outputs.\n",
    "# you'll find numerous judges who are listed multiple times for having gotten different college or university degrees over the years.\n",
    "if any(name in [\"judges\", \"demographics\", \"nominations\", \"nominees\",] for name in problematic_dfs):\n",
    "    logger.warning(f\"⚠️ Found non-unique IDs in: {', '.join(problematic_dfs)}\")\n",
    "    for df_name in problematic_dfs:\n",
    "        result = uniqueness_results[df_name]\n",
    "        logger.warning(f\"\\nDuplicates in {df_name}:\")\n",
    "        display(result['duplicate_rows'])\n",
    "else:\n",
    "    \n",
    "    logger.info(\"✓ All ID fields are unique across unique-ID-required dataframes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Data to Raw Directory\n",
    "\n",
    "Save the datasets to the raw data directory for use by downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataframes to /home/wsl2ubuntuuser/nomination_predictor/data/raw...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved 4,022 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/judges.csv\n",
      "  ✓ Saved 4,022 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/demographics.csv\n",
      "  ✓ Saved 8,040 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/education.csv\n",
      "  ✓ Saved 4,720 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/federal_judicial_service.csv\n",
      "  ✓ Saved 828 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/other_nominations_recess.csv\n",
      "  ✓ Saved 611 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/other_federal_judicial_service.csv\n",
      "  ✓ Saved 19,003 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/professional_career.csv\n",
      "  ✓ Saved 4,720 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/seat_timeline.csv\n",
      "  ✓ Saved 80 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/nominations.csv\n",
      "  ✓ Saved 80 records to /home/wsl2ubuntuuser/nomination_predictor/data/raw/nominees.csv\n",
      "\n",
      "✅ Successfully saved 10 dataframes to /home/wsl2ubuntuuser/nomination_predictor/data/raw\n",
      "✓ Saved 10 files to /home/wsl2ubuntuuser/nomination_predictor/data/raw\n",
      "✓ Created manifest: fjc_data_manifest_20250712.txt\n"
     ]
    }
   ],
   "source": [
    "# Save data to the raw data directory\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from nomination_predictor.config import RAW_DATA_DIR\n",
    "\n",
    "# Create the raw data directory if it doesn't exist\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Add a timestamp for the manifest\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Save each FJC dataframe\n",
    "# Save all dataframes to the raw data directory\n",
    "print(f\"Saving dataframes to {RAW_DATA_DIR}...\")\n",
    "saved_files = []\n",
    "\n",
    "# Ensure the output directory exists\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save all dataframes from the all_dataframes collection\n",
    "for name, df in all_dataframes.items():\n",
    "    if df is not None and not df.empty:\n",
    "        try:\n",
    "            # Create filename\n",
    "            output_file = RAW_DATA_DIR / f\"{name}.csv\"\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(output_file, index=False)\n",
    "            saved_files.append(f\"{name}.csv\")\n",
    "            print(f\"  ✓ Saved {len(df):,} records to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error saving {name}: {str(e)}\")\n",
    "\n",
    "# Print summary\n",
    "if saved_files:\n",
    "    print(f\"\\n✅ Successfully saved {len(saved_files)} dataframes to {RAW_DATA_DIR}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No dataframes were saved - check if all_dataframes is populated correctly\")\n",
    "\n",
    "# Create a manifest file to track what was saved and when\n",
    "manifest_content = f\"\"\"# FJC Data Processing Manifest\n",
    "Processed on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "Note: Only column names are normalized (lowercase with underscores), data values remain unchanged\n",
    "Files saved:\n",
    "{chr(10).join(['- ' + file for file in saved_files])}\n",
    "\"\"\"\n",
    "\n",
    "with open(RAW_DATA_DIR / f\"fjc_data_manifest_{timestamp}.txt\", \"w\") as f:\n",
    "    f.write(manifest_content)\n",
    "\n",
    "print(f\"✓ Saved {len(saved_files)} files to {RAW_DATA_DIR}\")\n",
    "print(f\"✓ Created manifest: fjc_data_manifest_{timestamp}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nominations to cache file: /home/wsl2ubuntuuser/nomination_predictor/data/raw/nominations.csv\n",
      "✓ Saved 80 nominations to cache\n",
      "Saving nominees to cache file: /home/wsl2ubuntuuser/nomination_predictor/data/raw/nominees.csv\n",
      "✓ Saved 80 nominees to cache\n"
     ]
    }
   ],
   "source": [
    "# Save Congress API retrieved nominations to cache file\n",
    "if nominations_df is not None and not nominations_df.empty:\n",
    "    # Ensure directory exists\n",
    "    os.makedirs(os.path.dirname(nominations_cache_file), exist_ok=True)\n",
    "    print(f\"Saving nominations to cache file: {nominations_cache_file}\")\n",
    "    nominations_df.to_csv(nominations_cache_file, index=False)\n",
    "    print(f\"✓ Saved {len(nominations_df)} nominations to cache\")\n",
    "    \n",
    "if nominees_df is not None and not nominees_df.empty:\n",
    "    # Ensure directory exists\n",
    "    os.makedirs(os.path.dirname(nominees_cache_file), exist_ok=True)\n",
    "    print(f\"Saving nominees to cache file: {nominees_cache_file}\")\n",
    "    nominees_df.to_csv(nominees_cache_file, index=False)\n",
    "    print(f\"✓ Saved {len(nominees_df)} nominees to cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded Federal Judicial Center (FJC) data, the canonical source for judicial seats and judges\n",
    "2. Built the seat timeline dataframe\n",
    "3. Fetched judicial nominations from the Congress.gov API\n",
    "4. Saved all datasets to the raw data directory for further processing by downstream notebooks\n",
    "\n",
    "The next notebook (e.g. 1.##-nw-feature-engineering.ipynb) will load these datasets, clean them, and engineer features for modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
