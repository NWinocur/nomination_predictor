{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching: FJC and Congress.gov API\n",
    "\n",
    "This notebook is responsible for fetching and initially processing data from our primary sources:\n",
    "\n",
    "1. Federal Judicial Center (FJC) CSV and Excel files\n",
    "2. Congress.gov API judicial nomination data\n",
    "\n",
    "According to the project architecture, this notebook will:\n",
    "1. Download or use cached data from the FJC and Congress.gov API\n",
    "2. Perform minimal transformations to convert to dataframes\n",
    "3. Save the resulting dataframes to `data/raw` for further processing by downstream notebooks\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from nomination_predictor.config import (EXTERNAL_DATA_DIR, INTERIM_DATA_DIR,\n",
    "                                         PROCESSED_DATA_DIR, RAW_DATA_DIR)\n",
    "from nomination_predictor.congress_api import CongressAPIClient\n",
    "from nomination_predictor.fjc_data import (FJC_DATA_DIR, build_seat_timeline,\n",
    "                                           get_predecessor_info, load_fjc_csv,\n",
    "                                           load_judges_data)\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Federal Judicial Center (FJC) Data\n",
    "\n",
    "The FJC data is our canonical source for judicial seat timelines, judge demographics, and nomination failures.\n",
    "\n",
    "### Check if FJC data exists or download if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the FJC data directory exists and contains expected files\n",
    "required_files = [\n",
    "    'federal-judicial-service.csv',\n",
    "    'judges.csv',\n",
    "]\n",
    "\n",
    "# Optional files\n",
    "optional_files = [\n",
    "    'demographics.csv',\n",
    "    'nominations-unsuccessful.csv',\n",
    "]\n",
    "\n",
    "# Check required files\n",
    "missing_files = []\n",
    "for file in required_files:\n",
    "    if not (FJC_DATA_DIR / file).exists():\n",
    "        missing_files.append(file)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"⚠️ Missing required FJC data files: {missing_files}\")\n",
    "    print(\"Please download the FJC data files from the Federal Judicial Center website and place them in:\")\n",
    "    print(f\"  {FJC_DATA_DIR}\")\n",
    "    print(\"\\nDownload links:\")\n",
    "    print(\"  - https://www.fjc.gov/history/judges/biographical-directory-federal-judges-export\")\n",
    "    print(\"  - https://www.fjc.gov/history/judges/diversity-bench\")\n",
    "else:\n",
    "    print(f\"✓ All required FJC data files found in {FJC_DATA_DIR}\")\n",
    "    \n",
    "    # Check optional files\n",
    "    for file in optional_files:\n",
    "        if (FJC_DATA_DIR / file).exists():\n",
    "            print(f\"  ✓ Optional file found: {file}\")\n",
    "        else:\n",
    "            print(f\"  ℹ️ Optional file not found: {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FJC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the service data\n",
    "try:\n",
    "    service_df = load_fjc_csv('federal-judicial-service.csv')\n",
    "    print(f\"Loaded service data: {len(service_df)} records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: federal-judicial-service.csv not found\")\n",
    "    service_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load judges data with demographics\n",
    "try:\n",
    "    judges_df = load_judges_data(include_demographics=True)\n",
    "    print(f\"Loaded judges data: {len(judges_df)} records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: judges.csv not found\")\n",
    "    judges_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Seat Timeline (Master Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the seat timeline if we have service data\n",
    "if not service_df.empty:\n",
    "    seat_timeline_df = build_seat_timeline(service_df)\n",
    "    print(f\"Built seat timeline: {len(seat_timeline_df)} records\")\n",
    "    \n",
    "    # Preview the seat timeline\n",
    "    seat_timeline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predecessor lookup table\n",
    "if 'seat_timeline_df' in locals():\n",
    "    predecessor_lookup = get_predecessor_info(seat_timeline_df)\n",
    "    print(f\"Created predecessor lookup: {len(predecessor_lookup)} records\")\n",
    "    \n",
    "    # Preview the predecessor lookup\n",
    "    predecessor_lookup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Congress.gov API Data\n",
    "\n",
    "The Congress.gov API provides detailed information about judicial nominations, including:\n",
    "- Nomination date\n",
    "- Nominee information\n",
    "- Confirmation status and date\n",
    "- Committee actions\n",
    "\n",
    "### Setup API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if API key is available\n",
    "api_key = os.environ.get(\"CONGRESS_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"❌ Error: CONGRESS_API_KEY environment variable not set\")\n",
    "    print(\"Please set the CONGRESS_API_KEY environment variable to your Congress.gov API key\")\n",
    "    print(\"You can request an API key at: https://api.congress.gov/sign-up/\")\n",
    "else:\n",
    "    print(\"✓ Congress API key found in environment variables\")\n",
    "    # Initialize the API client\n",
    "    congress_client = CongressAPIClient(api_key)\n",
    "    print(\"✓ Congress API client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Judicial Nominations from Recent Congresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch judicial nominations from recent congresses\n",
    "# Congress numbering: 116th (2019-2021), 117th (2021-2023), 118th (2023-2025)\n",
    "\n",
    "if 'congress_client' in locals():\n",
    "    congresses = [118, 117, 116]  # Most recent three congresses\n",
    "    all_nominations = []\n",
    "    \n",
    "    for congress in congresses:\n",
    "        try:\n",
    "            print(f\"Fetching judicial nominations for the {congress}th Congress...\")\n",
    "            nominations = congress_client.get_judicial_nominations(congress)\n",
    "            print(f\"  ✓ Retrieved {len(nominations)} judicial nominations\")\n",
    "            all_nominations.extend(nominations)\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error fetching nominations for {congress}th Congress: {str(e)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    nominations_df = pd.DataFrame(all_nominations)\n",
    "    print(f\"\\nTotal nominations retrieved: {len(nominations_df)}\")\n",
    "    \n",
    "    # Preview the nominations\n",
    "    if not nominations_df.empty:\n",
    "        nominations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crosswalk and Join Data Sources\n",
    "\n",
    "Now we'll crosswalk the Congress.gov nomination data to the FJC seat timeline using the nomination-to-seat matching logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.fjc_data import crosswalk_congress_api\n",
    "\n",
    "# Crosswalk if we have both datasets\n",
    "if 'nominations_df' in locals() and 'seat_timeline_df' in locals() and 'judges_df' in locals():\n",
    "    crosswalked_df = crosswalk_congress_api(\n",
    "        nominations_df,\n",
    "        seat_timeline_df,\n",
    "        judges_df\n",
    "    )\n",
    "    \n",
    "    print(f\"Crosswalked nominations: {len(crosswalked_df)} records\")\n",
    "    print(f\"Match statistics:\\n{crosswalked_df['seat_match_method'].value_counts()}\")\n",
    "    \n",
    "    # Preview crosswalked data\n",
    "    crosswalked_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Master Dataset\n",
    "\n",
    "Now we'll create the master dataset by joining the seat timeline with the crosswalked nominations data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.fjc_data import create_master_dataset\n",
    "\n",
    "# Create master dataset if we have both datasets\n",
    "if 'seat_timeline_df' in locals() and 'crosswalked_df' in locals():\n",
    "    master_df = create_master_dataset(\n",
    "        seat_timeline_df,\n",
    "        crosswalked_df\n",
    "    )\n",
    "    \n",
    "    print(f\"Created master dataset: {len(master_df)} records\")\n",
    "    \n",
    "    # Preview master dataset\n",
    "    master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Data to Raw Directory\n",
    "\n",
    "Save the datasets to the raw data directory for use by downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save seat timeline\n",
    "if 'seat_timeline_df' in locals() and not seat_timeline_df.empty:\n",
    "    output_path = RAW_DATA_DIR / \"seat_timeline.csv\"\n",
    "    seat_timeline_df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved seat timeline to {output_path}\")\n",
    "\n",
    "# Save crosswalked nominations\n",
    "if 'crosswalked_df' in locals() and not crosswalked_df.empty:\n",
    "    output_path = RAW_DATA_DIR / \"crosswalked_nominations.csv\"\n",
    "    crosswalked_df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved crosswalked nominations to {output_path}\")\n",
    "    \n",
    "# Save master dataset\n",
    "if 'master_df' in locals() and not master_df.empty:\n",
    "    output_path = RAW_DATA_DIR / \"master_dataset.csv\"\n",
    "    master_df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved master dataset to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded Federal Judicial Center (FJC) data, the canonical source for judicial seats and judges\n",
    "2. Built the seat timeline as our master table\n",
    "3. Fetched judicial nominations from the Congress.gov API\n",
    "4. Crosswalked the nomination data to FJC seat IDs\n",
    "5. Created a master dataset joining these sources\n",
    "6. Saved all datasets to the raw data directory for further processing by downstream notebooks\n",
    "\n",
    "The next notebook (1.00-nw-data-cleaning-feature-creation.ipynb) will load these datasets, clean them, and engineer features for modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
