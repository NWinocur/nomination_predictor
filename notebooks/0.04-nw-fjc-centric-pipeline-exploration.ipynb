{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FJC-Centric Pipeline Exploration\n",
    "\n",
    "This notebook demonstrates the new Federal Judicial Center (FJC) centric data pipeline for the nomination predictor project. The FJC data serves as the canonical source for:\n",
    "- Judicial seat timelines\n",
    "- Judge demographics\n",
    "- Nomination failures\n",
    "\n",
    "This notebook will:\n",
    "1. Load and validate FJC CSV files\n",
    "2. Build the seat timeline as the master table\n",
    "3. Process judge demographic data\n",
    "4. Create the predecessor lookup table\n",
    "5. Fetch judicial nominations from Congress.gov API\n",
    "6. Crosswalk Congress.gov data with FJC seat IDs\n",
    "7. Create a master dataset by joining these sources\n",
    "8. Visualize and validate data quality\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from nomination_predictor.config import (\n",
    "    EXTERNAL_DATA_DIR,\n",
    "    RAW_DATA_DIR,\n",
    "    INTERIM_DATA_DIR,\n",
    "    PROCESSED_DATA_DIR\n",
    ")\n",
    "from nomination_predictor.fjc_data import FJC_DATA_DIR, crosswalk_congress_api\n",
    "from nomination_predictor.fjc_processor import (\n",
    "    validate_data_files,\n",
    "    process_fjc_data,\n",
    "    test_date_parsing\n",
    ")\n",
    "from nomination_predictor.congress_api import CongressAPIClient\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FJC Data Validation\n",
    "\n",
    "First, we'll check if the required FJC data files exist in the expected directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for required FJC data files\n",
    "valid_files = validate_data_files()\n",
    "\n",
    "if not valid_files:\n",
    "    print(\"\\nPlease download the required FJC data files from:\")\n",
    "    print(\"  - https://www.fjc.gov/history/judges/biographical-directory-federal-judges-export\")\n",
    "    print(\"  - https://www.fjc.gov/history/judges/diversity-bench\")\n",
    "    print(f\"\\nAnd place them in: {FJC_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Parsing Testing\n",
    "\n",
    "The FJC data contains dates in various formats, including pre-1900 dates which require special handling. Let's test our date parsing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate date parsing functionality\n",
    "test_date_parsing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process FJC Data\n",
    "\n",
    "Now we'll process the FJC data files to create the seat timeline, judge data, and predecessor lookup table. We'll run this in validation mode first to check for data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process FJC data in validation mode (doesn't save files)\n",
    "seat_timeline_df, judges_df, predecessor_df = process_fjc_data(\n",
    "    output_dir=INTERIM_DATA_DIR,\n",
    "    validate_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore FJC Data\n",
    "\n",
    "### Explore the Seat Timeline\n",
    "\n",
    "The seat timeline is our master table, with one row per incumbent-seat tenure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the seat timeline\n",
    "if seat_timeline_df is not None:\n",
    "    print(f\"Seat timeline shape: {seat_timeline_df.shape}\")\n",
    "    print(f\"Number of unique seats: {seat_timeline_df['seat_id'].nunique()}\")\n",
    "    print(\"\\nSample records:\")\n",
    "    display(seat_timeline_df.head())\n",
    "    \n",
    "    # Basic column info\n",
    "    print(\"\\nColumn data types:\")\n",
    "    display(seat_timeline_df.dtypes)\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values by column:\")\n",
    "    missing = seat_timeline_df.isna().sum().to_frame(name='Missing')\n",
    "    missing['Percent'] = missing['Missing'] / len(seat_timeline_df) * 100\n",
    "    display(missing[missing['Missing'] > 0].sort_values('Missing', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Judicial Tenures\n",
    "\n",
    "Let's create some visualizations to understand the tenure patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seat_timeline_df is not None:\n",
    "    # Calculate tenure length in years\n",
    "    seat_timeline_df['tenure_years'] = (seat_timeline_df['termination_date'] - seat_timeline_df['commission_date']).dt.days / 365.25\n",
    "    \n",
    "    # Plot tenure distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(seat_timeline_df['tenure_years'].dropna(), bins=50, alpha=0.7, color='steelblue')\n",
    "    plt.axvline(seat_timeline_df['tenure_years'].median(), color='red', linestyle='--', \n",
    "                label=f'Median: {seat_timeline_df[\"tenure_years\"].median():.1f} years')\n",
    "    plt.title('Distribution of Judicial Tenures')\n",
    "    plt.xlabel('Tenure (years)')\n",
    "    plt.ylabel('Number of Judges')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"Tenure length statistics (years):\")\n",
    "    print(seat_timeline_df['tenure_years'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Judge Demographics\n",
    "\n",
    "Let's examine the judge demographic data, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if judges_df is not None:\n",
    "    print(f\"Judges data shape: {judges_df.shape}\")\n",
    "    print(\"\\nSample records:\")\n",
    "    display(judges_df.head())\n",
    "    \n",
    "    # Check if demographic columns are present\n",
    "    demographic_cols = ['gender', 'race', 'birth_year']\n",
    "    available_demo_cols = [col for col in demographic_cols if col in judges_df.columns]\n",
    "    \n",
    "    if available_demo_cols:\n",
    "        print(\"\\nDemographic information available:\")\n",
    "        for col in available_demo_cols:\n",
    "            print(f\"\\n{col.title()} distribution:\")\n",
    "            if col in ['gender', 'race']:\n",
    "                display(judges_df[col].value_counts(dropna=False))\n",
    "            elif col == 'birth_year':\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                judges_df['birth_year'].hist(bins=30, alpha=0.7, color='steelblue')\n",
    "                plt.title('Distribution of Judge Birth Years')\n",
    "                plt.xlabel('Birth Year')\n",
    "                plt.ylabel('Number of Judges')\n",
    "                plt.grid(alpha=0.3)\n",
    "                plt.show()\n",
    "    else:\n",
    "        print(\"\\nNo demographic information available in the judges data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Predecessor Lookup Table\n",
    "\n",
    "The predecessor lookup table is crucial for crosswalking with other data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predecessor_df is not None:\n",
    "    print(f\"Predecessor lookup shape: {predecessor_df.shape}\")\n",
    "    print(f\"Number of unique seats: {predecessor_df['seat_id'].nunique()}\")\n",
    "    print(\"\\nSample records:\")\n",
    "    display(predecessor_df.head())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values by column:\")\n",
    "    missing = predecessor_df.isna().sum().to_frame(name='Missing')\n",
    "    missing['Percent'] = missing['Missing'] / len(predecessor_df) * 100\n",
    "    display(missing[missing['Missing'] > 0].sort_values('Missing', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Congress.gov API Integration\n",
    "\n",
    "Now we'll integrate Congress.gov API data to supplement our FJC data with nomination details.\n",
    "\n",
    "### Setup API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if API key is available\n",
    "api_key = os.environ.get(\"CONGRESS_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"‚ùå Error: CONGRESS_API_KEY environment variable not set\")\n",
    "    print(\"Please set the CONGRESS_API_KEY environment variable to your Congress.gov API key\")\n",
    "    print(\"You can request an API key at: https://api.congress.gov/sign-up/\")\n",
    "else:\n",
    "    print(\"‚úì Congress API key found in environment variables\")\n",
    "    # Initialize the API client\n",
    "    congress_client = CongressAPIClient(api_key)\n",
    "    print(\"‚úì Congress API client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Judicial Nominations from Recent Congresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch judicial nominations from recent congresses\n",
    "# Congress numbering: 116th (2019-2021), 117th (2021-2023), 118th (2023-2025)\n",
    "\n",
    "if 'congress_client' in locals():\n",
    "    congresses = [118, 117, 116]  # Most recent three congresses\n",
    "    all_nominations = []\n",
    "    \n",
    "    for congress in congresses:\n",
    "        try:\n",
    "            print(f\"Fetching judicial nominations for the {congress}th Congress...\")\n",
    "            nominations = congress_client.get_judicial_nominations(congress)\n",
    "            print(f\"  ‚úì Retrieved {len(nominations)} judicial nominations\")\n",
    "            all_nominations.extend(nominations)\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error fetching nominations for {congress}th Congress: {str(e)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    nominations_df = pd.DataFrame(all_nominations)\n",
    "    print(f\"\\nTotal nominations retrieved: {len(nominations_df)}\")\n",
    "    \n",
    "    # Preview the nominations\n",
    "    if not nominations_df.empty:\n",
    "        display(nominations_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Crosswalk and Join Data Sources\n",
    "\n",
    "Now we'll crosswalk the Congress.gov nomination data to the FJC seat timeline using the nomination-to-seat matching logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosswalk if we have both datasets\n",
    "if 'nominations_df' in locals() and not nominations_df.empty and seat_timeline_df is not None and judges_df is not None:\n",
    "    crosswalked_df = crosswalk_congress_api(\n",
    "        nominations_df,\n",
    "        seat_timeline_df,\n",
    "        judges_df\n",
    "    )\n",
    "    \n",
    "    print(f\"Crosswalked nominations: {len(crosswalked_df)} records\")\n",
    "    print(f\"Match statistics:\\n{crosswalked_df['seat_match_method'].value_counts()}\")\n",
    "    \n",
    "    # Preview crosswalked data\n",
    "    display(crosswalked_df.head())\n",
    "else:\n",
    "    print(\"Cannot perform crosswalk - missing one or more required datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Crosswalk Quality\n",
    "\n",
    "Let's assess the quality of our crosswalk by examining match rates and potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'crosswalked_df' in locals() and not crosswalked_df.empty:\n",
    "    # Calculate match rate\n",
    "    match_rate = (crosswalked_df['seat_match_method'] != 'unmatched').mean() * 100\n",
    "    print(f\"Match rate: {match_rate:.2f}%\")\n",
    "    \n",
    "    # Examine unmatched nominations\n",
    "    unmatched = crosswalked_df[crosswalked_df['seat_match_method'] == 'unmatched']\n",
    "    if len(unmatched) > 0:\n",
    "        print(f\"\\nSample of unmatched nominations ({len(unmatched)} total):\")\n",
    "        display(unmatched.head())\n",
    "        \n",
    "        # Check patterns in unmatched nominations\n",
    "        if 'description' in unmatched.columns:\n",
    "            print(\"\\nCommon patterns in unmatched nomination descriptions:\")\n",
    "            display(unmatched['description'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Master Dataset\n",
    "\n",
    "Now we'll create the master dataset by joining the seat timeline with the crosswalked nominations data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.fjc_data import create_master_dataset\n",
    "\n",
    "# Create master dataset if we have both datasets\n",
    "if 'seat_timeline_df' in locals() and 'crosswalked_df' in locals() and not crosswalked_df.empty:\n",
    "    master_df = create_master_dataset(\n",
    "        seat_timeline_df,\n",
    "        crosswalked_df\n",
    "    )\n",
    "    \n",
    "    print(f\"Created master dataset: {len(master_df)} records\")\n",
    "    \n",
    "    # Preview master dataset\n",
    "    display(master_df.head())\n",
    "else:\n",
    "    print(\"Cannot create master dataset - missing required input datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data\n",
    "\n",
    "Now we can save our processed datasets for use in downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the user if they want to save the processed data\n",
    "save_data = input(\"Save processed data files? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "if save_data:\n",
    "    # Save seat timeline\n",
    "    if seat_timeline_df is not None and not seat_timeline_df.empty:\n",
    "        output_path = RAW_DATA_DIR / \"seat_timeline.csv\"\n",
    "        seat_timeline_df.to_csv(output_path, index=False)\n",
    "        print(f\"‚úì Saved seat timeline to {output_path}\")\n",
    "\n",
    "    # Save crosswalked nominations\n",
    "    if 'crosswalked_df' in locals() and not crosswalked_df.empty:\n",
    "        output_path = RAW_DATA_DIR / \"crosswalked_nominations.csv\"\n",
    "        crosswalked_df.to_csv(output_path, index=False)\n",
    "        print(f\"‚úì Saved crosswalked nominations to {output_path}\")\n",
    "        \n",
    "    # Save master dataset\n",
    "    if 'master_df' in locals() and not master_df.empty:\n",
    "        output_path = RAW_DATA_DIR / \"master_dataset.csv\"\n",
    "        master_df.to_csv(output_path, index=False)\n",
    "        print(f\"‚úì Saved master dataset to {output_path}\")\n",
    "        \n",
    "    # Save judges data\n",
    "    if judges_df is not None and not judges_df.empty:\n",
    "        output_path = RAW_DATA_DIR / \"judges.csv\"\n",
    "        judges_df.to_csv(output_path, index=False)\n",
    "        print(f\"‚úì Saved judges data to {output_path}\")\n",
    "else:\n",
    "    print(\"Skipped saving data files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded and validated Federal Judicial Center (FJC) data files\n",
    "2. Built the seat timeline as our master table for judicial tenures\n",
    "3. Explored judge demographics from the FJC\n",
    "4. Created the predecessor lookup table for crosswalking\n",
    "5. Fetched and processed judicial nominations from the Congress.gov API\n",
    "6. Crosswalked the nomination data to FJC seat IDs\n",
    "7. Created and validated a master dataset joining these sources\n",
    "8. Saved the processed data for downstream use\n",
    "\n",
    "This FJC-centric pipeline provides a more reliable, comprehensive, and maintainable approach to judicial nomination data than the previous HTML/PDF scraping approach. The next notebook (1.00-nw-data-cleaning-feature-creation.ipynb) will use these datasets for feature engineering and modeling preparation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
