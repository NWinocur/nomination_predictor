{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd428ca2",
   "metadata": {},
   "source": [
    "# Notebook 1 – Data Cleaning, Feature Engineering, & Entity Resolution\n",
    "**Project:** Judicial Vacancy → Nomination/Confirmation Pipeline\n",
    "\n",
    "*Initial draft generated via ChatGPT model o3 on 2025-07-12T02:40:38.399372Z*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ea97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from nomination_predictor.config import INTERIM_DATA_DIR, RAW_DATA_DIR\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acce299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helper: clean / normalize names\n",
    "def clean_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).upper()\n",
    "    name = re.sub(r\"[\\.,]\", \"\", name)          # drop punctuation\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name\n",
    "\n",
    "def split_name(name: str):\n",
    "    \"\"\"\n",
    "    Very naive splitter: returns first, middle (maybe empty), last\n",
    "    \"\"\"\n",
    "    parts = clean_name(name).split()\n",
    "    if not parts:\n",
    "        return \"\", \"\", \"\"\n",
    "    if len(parts) == 1:\n",
    "        return parts[0], \"\", \"\"\n",
    "    if len(parts) == 2:\n",
    "        return parts[0], \"\", parts[1]\n",
    "    return parts[0], \" \".join(parts[1:-1]), parts[-1]\n",
    "\n",
    "def normalised_court(text: str) -> str:\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.upper().replace(\"UNITED STATES\", \"\").replace(\"U.S.\", \"\").strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3df33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 4022 judges 4720 service records 285 congress nominees 285 nominations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Expected input files (produced by Notebook 0)\n",
    "fjc_judges    = pd.read_csv(RAW_DATA_DIR / \"judges.csv\")\n",
    "fjc_service   = pd.read_csv(RAW_DATA_DIR / \"federal_judicial_service.csv\")\n",
    "cong_nominees = pd.read_csv(RAW_DATA_DIR / \"congress_nominees_cache.csv\")\n",
    "cong_noms     = pd.read_csv(RAW_DATA_DIR / \"congress_nominations_cache.csv\")\n",
    "\n",
    "print(\"Loaded:\",\n",
    "      len(fjc_judges), \"judges\",\n",
    "      len(fjc_service), \"service records\",\n",
    "      len(cong_nominees), \"congress nominees\",\n",
    "      len(cong_noms), \"nominations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a767be",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'full_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'full_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Clean Congress nominees ------------------------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cong_nominees[\u001b[33m\"\u001b[39m\u001b[33mfull_name_clean\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcong_nominees\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfull_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.apply(clean_name)\n\u001b[32m      3\u001b[39m cong_nominees[[\u001b[33m\"\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mmiddle\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mlast\u001b[39m\u001b[33m\"\u001b[39m]] = cong_nominees[\u001b[33m\"\u001b[39m\u001b[33mfull_name_clean\u001b[39m\u001b[33m\"\u001b[39m].apply(\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m n: pd.Series(split_name(n)))\n\u001b[32m      6\u001b[39m cong_nominees[\u001b[33m\"\u001b[39m\u001b[33mcourt_clean\u001b[39m\u001b[33m\"\u001b[39m] = cong_nominees[\u001b[33m\"\u001b[39m\u001b[33morganization\u001b[39m\u001b[33m\"\u001b[39m].apply(normalised_court)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'full_name'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Clean Congress nominees ------------------------------------------------\n",
    "cong_nominees[\"full_name_clean\"] = cong_nominees[\"full_name\"].apply(clean_name)\n",
    "cong_nominees[[\"first\",\"middle\",\"last\"]] = cong_nominees[\"full_name_clean\"].apply(\n",
    "    lambda n: pd.Series(split_name(n)))\n",
    "\n",
    "cong_nominees[\"court_clean\"] = cong_nominees[\"organization\"].apply(normalised_court)\n",
    "cong_nominees[\"nomination_date\"] = pd.to_datetime(cong_nominees[\"nomination_date\"])\n",
    "\n",
    "# --- Clean FJC judges -------------------------------------------------------\n",
    "fjc_judges[\"full_name_clean\"] = fjc_judges[\"name_full\"].apply(clean_name)\n",
    "fjc_judges[[\"first\",\"middle\",\"last\"]] = fjc_judges[\"full_name_clean\"].apply(\n",
    "    lambda n: pd.Series(split_name(n)))\n",
    "\n",
    "# We'll need a mapping from nid to service records for date & court validation\n",
    "fjc_service[\"court_clean\"] = fjc_service[\"court\"].apply(normalised_court)\n",
    "fjc_service[\"nomination_date\"] = pd.to_datetime(fjc_service[\"nomination_date\"], errors=\"coerce\")\n",
    "fjc_service[\"commission_date\"] = pd.to_datetime(fjc_service[\"commission_date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26795292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Block by last name exact match\n",
    "blocks = {}\n",
    "for lname, group in fjc_judges.groupby(\"last\"):\n",
    "    blocks[lname] = group\n",
    "\n",
    "def candidate_fjc_rows(row):\n",
    "    return blocks.get(row[\"last\"], pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_match(row):\n",
    "    candidates = candidate_fjc_rows(row)\n",
    "    if candidates.empty:\n",
    "        return pd.NA, 0.0\n",
    "    # Compute combined score: name similarity + court similarity + date proximity\n",
    "    best_score = 0.0\n",
    "    best_nid = pd.NA\n",
    "    for _, cand in candidates.iterrows():\n",
    "        name_score = fuzz.token_set_ratio(row[\"full_name_clean\"], cand[\"full_name_clean\"])\n",
    "        # Use service records to find any matching nomination date\n",
    "        entries = fjc_service[fjc_service[\"nid\"] == cand[\"nid\"]]\n",
    "        date_score = 0\n",
    "        court_score = 0\n",
    "        if not entries.empty:\n",
    "            # Smallest absolute diff in days\n",
    "            diffs = (entries[\"nomination_date\"] - row[\"nomination_date\"]).abs().dt.days\n",
    "            date_score = 100 - diffs.min() if diffs.notna().any() else 0\n",
    "            # any court string overlap\n",
    "            if row[\"court_clean\"]:\n",
    "                if any(row[\"court_clean\"] in c for c in entries[\"court_clean\"]):\n",
    "                    court_score = 100\n",
    "                else:\n",
    "                    court_score = max(fuzz.partial_ratio(row[\"court_clean\"], c) for c in entries[\"court_clean\"])\n",
    "        total = 0.6*name_score + 0.3*date_score + 0.1*court_score\n",
    "        if total > best_score:\n",
    "            best_score, best_nid = total, cand[\"nid\"]\n",
    "    return best_nid, round(best_score,1)\n",
    "\n",
    "cong_nominees[[\"match_nid\",\"match_score\"]] = cong_nominees.apply(\n",
    "    best_match, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a709203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "THRESHOLD = 80\n",
    "matches = cong_nominees[cong_nominees[\"match_score\"] >= THRESHOLD].copy()\n",
    "print(f\"Matched {len(matches)}/{len(cong_nominees)} nominees with score ≥ {THRESHOLD}\")\n",
    "matches.to_csv(INTERIM_DATA_DIR / \"congress_fjc_nominee_matches.csv\", index=False)\n",
    "\n",
    "# Save the cleaned interim datasets for downstream notebooks\n",
    "cong_nominees.to_csv(INTERIM_DATA_DIR / \"congress_nominees_cleaned.csv\", index=False)\n",
    "fjc_judges.to_csv(INTERIM_DATA_DIR / \"fjc_judges_cleaned.csv\", index=False)\n",
    "fjc_service.to_csv(INTERIM_DATA_DIR / \"fjc_service_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
