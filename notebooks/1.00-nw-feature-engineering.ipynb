{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd428ca2",
   "metadata": {},
   "source": [
    "# Notebook 1 – Data Cleaning, Feature Engineering, & Entity Resolution\n",
    "**Project:** Judicial Vacancy → Nomination/Confirmation Pipeline\n",
    "\n",
    "*Initial draft generated via ChatGPT model o3 on 2025-07-12T02:40:38.399372Z*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 00:24:27.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mProject root: /home/wsl2ubuntuuser/nomination_predictor\u001b[0m\n",
      "\u001b[32m2025-07-12 00:24:27.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mConfiguration loaded\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from nomination_predictor.config import INTERIM_DATA_DIR, RAW_DATA_DIR\n",
    "from nomination_predictor.congress_api_utils import \\\n",
    "    enrich_congress_nominees_dataframe\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acce299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helper: clean / normalize names\n",
    "def clean_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).upper()\n",
    "    name = re.sub(r\"[\\.,]\", \"\", name)          # drop punctuation\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name\n",
    "\n",
    "def split_name(name: str):\n",
    "    \"\"\"\n",
    "    Very naive splitter: returns first, middle (maybe empty), last\n",
    "    \"\"\"\n",
    "    parts = clean_name(name).split()\n",
    "    if not parts:\n",
    "        return \"\", \"\", \"\"\n",
    "    if len(parts) == 1:\n",
    "        return parts[0], \"\", \"\"\n",
    "    if len(parts) == 2:\n",
    "        return parts[0], \"\", parts[1]\n",
    "    return parts[0], \" \".join(parts[1:-1]), parts[-1]\n",
    "\n",
    "def normalised_court(text: str) -> str:\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.upper().replace(\"UNITED STATES\", \"\").replace(\"U.S.\", \"\").strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3df33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 00:23:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_and_prepare_dataframes\u001b[0m - \u001b[1mLoaded 4022 judges, 4720 service records, 285 congress nominees, 285 nominations\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 4022 judges 4720 service records 285 congress nominees 285 nominations\n"
     ]
    }
   ],
   "source": [
    "from nomination_predictor.feature_engineering_helpers import \\\n",
    "    load_and_prepare_dataframes\n",
    "\n",
    "# Load and prepare all dataframes\n",
    "dfs = load_and_prepare_dataframes(RAW_DATA_DIR)\n",
    "cong_nominees = dfs[\"cong_nominees\"]  # This now has all the derived fields\n",
    "fjc_judges    = dfs[\"fjc_judges\"]   \n",
    "fjc_service   = dfs[\"fjc_service\"]\n",
    "cong_noms     = dfs[\"cong_noms\"]\n",
    "\n",
    "print(\"Loaded:\",\n",
    "      len(fjc_judges), \"judges\",\n",
    "      len(fjc_service), \"service records\",\n",
    "      len(cong_nominees), \"congress nominees\",\n",
    "      len(cong_noms), \"nominations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a767be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean Congress nominees ------------------------------------------------\n",
    "cong_nominees[\"full_name_clean\"] = cong_nominees[\"full_name\"].apply(clean_name)\n",
    "cong_nominees[[\"first\",\"middle\",\"last\"]] = cong_nominees[\"full_name_clean\"].apply(\n",
    "    lambda n: pd.Series(split_name(n)))\n",
    "\n",
    "cong_nominees[\"court_clean\"] = cong_nominees[\"organization\"].apply(normalised_court)\n",
    "cong_nominees[\"nomination_date\"] = pd.to_datetime(cong_nominees[\"nomination_date\"])\n",
    "\n",
    "# --- Clean FJC judges -------------------------------------------------------\n",
    "fjc_judges[\"full_name_clean\"] = fjc_judges[\"name_full\"].apply(clean_name)\n",
    "fjc_judges[[\"first\",\"middle\",\"last\"]] = fjc_judges[\"full_name_clean\"].apply(\n",
    "    lambda n: pd.Series(split_name(n)))\n",
    "\n",
    "# We'll need a mapping from nid to service records for date & court validation\n",
    "fjc_service[\"court_clean\"] = fjc_service[\"court_name\"].apply(normalised_court)\n",
    "fjc_service[\"nomination_date\"] = pd.to_datetime(fjc_service[\"nomination_date\"], errors=\"coerce\")\n",
    "fjc_service[\"commission_date\"] = pd.to_datetime(fjc_service[\"commission_date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26795292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Block by last name exact match\n",
    "blocks = {}\n",
    "for lname, group in fjc_judges.groupby(\"last\"):\n",
    "    blocks[lname] = group\n",
    "\n",
    "def candidate_fjc_rows(row):\n",
    "    return blocks.get(row[\"last\"], pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_match(row):\n",
    "    candidates = candidate_fjc_rows(row)\n",
    "    if candidates.empty:\n",
    "        return pd.NA, 0.0\n",
    "    # Compute combined score: name similarity + court similarity + date proximity\n",
    "    best_score = 0.0\n",
    "    best_nid = pd.NA\n",
    "    for _, cand in candidates.iterrows():\n",
    "        name_score = fuzz.token_set_ratio(row[\"full_name_clean\"], cand[\"full_name_clean\"])\n",
    "        # Use service records to find any matching nomination date\n",
    "        entries = fjc_service[fjc_service[\"nid\"] == cand[\"nid\"]]\n",
    "        date_score = 0\n",
    "        court_score = 0\n",
    "        if not entries.empty:\n",
    "            # Smallest absolute diff in days\n",
    "            diffs = (entries[\"nomination_date\"] - row[\"nomination_date\"]).abs().dt.days\n",
    "            date_score = 100 - diffs.min() if diffs.notna().any() else 0\n",
    "            # any court string overlap\n",
    "            if row[\"court_clean\"]:\n",
    "                if any(row[\"court_clean\"] in c for c in entries[\"court_clean\"]):\n",
    "                    court_score = 100\n",
    "                else:\n",
    "                    court_score = max(fuzz.partial_ratio(row[\"court_clean\"], c) for c in entries[\"court_clean\"])\n",
    "        total = 0.6*name_score + 0.3*date_score + 0.1*court_score\n",
    "        if total > best_score:\n",
    "            best_score, best_nid = total, cand[\"nid\"]\n",
    "    return best_nid, round(best_score,1)\n",
    "\n",
    "cong_nominees[[\"match_nid\",\"match_score\"]] = cong_nominees.apply(\n",
    "    best_match, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a709203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 140/285 nominees with score ≥ 80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "THRESHOLD = 80\n",
    "matches = cong_nominees[cong_nominees[\"match_score\"] >= THRESHOLD].copy()\n",
    "print(f\"Matched {len(matches)}/{len(cong_nominees)} nominees with score ≥ {THRESHOLD}\")\n",
    "matches.to_csv(INTERIM_DATA_DIR / \"congress_fjc_nominee_matches.csv\", index=False)\n",
    "\n",
    "# Save the cleaned interim datasets for downstream notebooks\n",
    "cong_nominees.to_csv(INTERIM_DATA_DIR / \"congress_nominees_cleaned.csv\", index=False)\n",
    "fjc_judges.to_csv(INTERIM_DATA_DIR / \"fjc_judges_cleaned.csv\", index=False)\n",
    "fjc_service.to_csv(INTERIM_DATA_DIR / \"fjc_service_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
