{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd428ca2",
   "metadata": {},
   "source": [
    "# Notebook 1 – Data Cleaning, Feature Engineering, & Entity Resolution\n",
    "**Project:** Judicial Vacancy → Nomination/Confirmation Pipeline\n",
    "\n",
    "*Initial draft generated via ChatGPT model o3 on 2025-07-12T02:40:38.399372Z*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 10:35:29.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mProject root: /home/wsl2ubuntuuser/nomination_predictor\u001b[0m\n",
      "\u001b[32m2025-07-12 10:35:29.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mConfiguration loaded\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from nomination_predictor.config import INTERIM_DATA_DIR, RAW_DATA_DIR\n",
    "from nomination_predictor.congress_api_utils import \\\n",
    "    enrich_congress_nominees_dataframe\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acce299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helper: clean / normalize names\n",
    "def clean_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).upper()\n",
    "    name = re.sub(r\"[\\.,]\", \"\", name)          # drop punctuation\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name\n",
    "\n",
    "def split_name(name: str):\n",
    "    \"\"\"\n",
    "    Very naive splitter: returns first, middle (maybe empty), last\n",
    "    \"\"\"\n",
    "    parts = clean_name(name).split()\n",
    "    if not parts:\n",
    "        return \"\", \"\", \"\"\n",
    "    if len(parts) == 1:\n",
    "        return parts[0], \"\", \"\"\n",
    "    if len(parts) == 2:\n",
    "        return parts[0], \"\", parts[1]\n",
    "    return parts[0], \" \".join(parts[1:-1]), parts[-1]\n",
    "\n",
    "def normalised_court(text: str) -> str:\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.upper().replace(\"UNITED STATES\", \"\").replace(\"U.S.\", \"\").strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3df33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 10:35:29\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mload_and_prepare_dataframes\u001b[0m - \u001b[1mLoaded 4022 judges, 4720 service records, 285 congress nominees, 285 nominations\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 4022 judges 4720 service records 285 congress nominees 285 nominations\n"
     ]
    }
   ],
   "source": [
    "from nomination_predictor.feature_engineering_helpers import (\n",
    "    analyze_match_failures, load_and_prepare_dataframes)\n",
    "\n",
    "# Load and prepare all dataframes\n",
    "dfs = load_and_prepare_dataframes(RAW_DATA_DIR)\n",
    "cong_nominees = dfs[\"cong_nominees\"]  # This now has all the derived fields\n",
    "fjc_judges    = dfs[\"fjc_judges\"]   \n",
    "fjc_service   = dfs[\"fjc_service\"]\n",
    "cong_nominations = dfs[\"cong_nominations\"]\n",
    "\n",
    "print(\"Loaded:\",\n",
    "      len(fjc_judges), \"judges\",\n",
    "      len(fjc_service), \"service records\",\n",
    "      len(cong_nominees), \"congress nominees\",\n",
    "      len(cong_nominations), \"nominations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24052def",
   "metadata": {},
   "source": [
    "Drop non-judge roles from nominations & nominees list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3584bea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'nid'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'nid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Find nids of rows with non-judicial titles\u001b[39;00m\n\u001b[32m     12\u001b[39m non_judicial_mask = cong_nominations[\u001b[33m\"\u001b[39m\u001b[33mnominee_positiontitle\u001b[39m\u001b[33m\"\u001b[39m].str.contains(\u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(non_judicial_titles), na=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m nids_to_drop = \u001b[43mcong_nominations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnon_judicial_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.unique()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Log the number of non-judicial nominations being removed\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(nids_to_drop)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m unique nids with non-judicial titles\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexing.py:1184\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m   1183\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._get_value(*key, takeable=\u001b[38;5;28mself\u001b[39m._takeable)\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[32m   1187\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexing.py:1368\u001b[39m, in \u001b[36m_LocIndexer._getitem_tuple\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[32m   1367\u001b[39m     tup = \u001b[38;5;28mself\u001b[39m._expand_ellipsis(tup)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[32m   1371\u001b[39m tup = \u001b[38;5;28mself\u001b[39m._validate_tuple_indexer(tup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexing.py:1065\u001b[39m, in \u001b[36m_LocationIndexer._getitem_lowerdim\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[32m   1063\u001b[39m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[32m   1064\u001b[39m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m         section = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[32m   1069\u001b[39m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[32m   1070\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m section.ndim == \u001b[38;5;28mself\u001b[39m.ndim:\n\u001b[32m   1071\u001b[39m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[32m   1072\u001b[39m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexing.py:1431\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexing.py:1381\u001b[39m, in \u001b[36m_LocIndexer._get_label\u001b[39m\u001b[34m(self, label, axis)\u001b[39m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/generic.py:4306\u001b[39m, in \u001b[36mNDFrame.xs\u001b[39m\u001b[34m(self, key, axis, level, drop_level)\u001b[39m\n\u001b[32m   4304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n\u001b[32m   4305\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m drop_level:\n\u001b[32m-> \u001b[39m\u001b[32m4306\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   4307\u001b[39m     index = \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'nid'"
     ]
    }
   ],
   "source": [
    "# for each row in cong_nominations, if the \"nominee_positiontitle\" field contains any of the following \n",
    "# non-judge-title phrases (case-sensitively matched), then lookup that row's \"citation\" field and drop the row \n",
    "# containing that citation from BOTH the cong_nominations and cong_nominees dataframes, who are expected \n",
    "# to each have only had one row with that citation.\n",
    "non_judicial_titles = [\"Attorney\",\"Board\",\"Commission\",\"Director\",\"Marshal\",\"Assistant\",\"Representative\",\"Secretary of\",\"Member of\"]\n",
    "\n",
    "# Make a copy of the dataframes to avoid SettingWithCopyWarning\n",
    "cong_nominations = cong_nominations.copy()\n",
    "cong_nominees = cong_nominees.copy()\n",
    "\n",
    "# Find citations of rows with non-judicial titles\n",
    "non_judicial_mask = cong_nominations[\"nominee_positiontitle\"].str.contains('|'.join(non_judicial_titles), na=False)\n",
    "citations_to_drop = cong_nominations.loc[non_judicial_mask, \"citation\"].unique()\n",
    "\n",
    "# Log the number of non-judicial nominations being removed\n",
    "print(f\"Found {len(citations_to_drop)} unique citations with non-judicial titles\")\n",
    "\n",
    "# Filter out the non-judicial nominations\n",
    "original_nominations_count = len(cong_nominations)\n",
    "original_nominees_count = len(cong_nominees)\n",
    "\n",
    "cong_nominations = cong_nominations[~cong_nominations[\"citation\"].isin(citations_to_drop)]\n",
    "cong_nominees = cong_nominees[~cong_nominees[\"citation\"].isin(citations_to_drop)]\n",
    "\n",
    "# Log the results\n",
    "print(f\"Removed {original_nominations_count - len(cong_nominations)}/{original_nominations_count} non-judicial nominations\")\n",
    "print(f\"Removed {original_nominees_count - len(cong_nominees)}/{original_nominees_count} corresponding nominee records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a767be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean Congress nominees ------------------------------------------------\n",
    "cong_nominees[\"full_name_clean\"] = cong_nominees[\"full_name\"].apply(clean_name)\n",
    "cong_nominees[[\"first\",\"middle\",\"last\"]] = cong_nominees[\"full_name_clean\"].apply(\n",
    "    lambda n: pd.Series(split_name(n)))\n",
    "\n",
    "cong_nominees[\"court_clean\"] = cong_nominees[\"organization\"].apply(normalised_court)\n",
    "cong_nominees[\"nomination_date\"] = pd.to_datetime(cong_nominees[\"nomination_date\"])\n",
    "\n",
    "# --- Clean FJC judges -------------------------------------------------------\n",
    "fjc_judges[\"full_name_clean\"] = fjc_judges[\"name_full\"].apply(clean_name)\n",
    "fjc_judges[[\"first\",\"middle\",\"last\"]] = fjc_judges[\"full_name_clean\"].apply(\n",
    "    lambda n: pd.Series(split_name(n)))\n",
    "\n",
    "# We'll need a mapping from nid to service records for date & court validation\n",
    "fjc_service[\"court_clean\"] = fjc_service[\"court_name\"].apply(normalised_court)\n",
    "fjc_service[\"nomination_date\"] = pd.to_datetime(fjc_service[\"nomination_date\"], errors=\"coerce\")\n",
    "fjc_service[\"commission_date\"] = pd.to_datetime(fjc_service[\"commission_date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26795292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Block by last name exact match\n",
    "blocks = {}\n",
    "for lname, group in fjc_judges.groupby(\"last\"):\n",
    "    blocks[lname] = group\n",
    "\n",
    "def candidate_fjc_rows(row):\n",
    "    return blocks.get(row[\"last\"], pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_match(row):\n",
    "    candidates = candidate_fjc_rows(row)\n",
    "    if candidates.empty:\n",
    "        return pd.NA, 0.0\n",
    "    # Compute combined score: name similarity + court similarity + date proximity\n",
    "    best_score = 0.0\n",
    "    best_nid = pd.NA\n",
    "    for _, cand in candidates.iterrows():\n",
    "        name_score = fuzz.token_set_ratio(row[\"full_name_clean\"], cand[\"full_name_clean\"])\n",
    "        # Use service records to find any matching nomination date\n",
    "        entries = fjc_service[fjc_service[\"nid\"] == cand[\"nid\"]]\n",
    "        date_score = 0\n",
    "        court_score = 0\n",
    "        if not entries.empty:\n",
    "            # Smallest absolute diff in days\n",
    "            diffs = (entries[\"nomination_date\"] - row[\"nomination_date\"]).abs().dt.days\n",
    "            date_score = 100 - diffs.min() if diffs.notna().any() else 0\n",
    "            # any court string overlap\n",
    "            if row[\"court_clean\"]:\n",
    "                if any(row[\"court_clean\"] in c for c in entries[\"court_clean\"]):\n",
    "                    court_score = 100\n",
    "                else:\n",
    "                    court_score = max(fuzz.partial_ratio(row[\"court_clean\"], c) for c in entries[\"court_clean\"])\n",
    "        total = 0.6*name_score + 0.3*date_score + 0.1*court_score\n",
    "        if total > best_score:\n",
    "            best_score, best_nid = total, cand[\"nid\"]\n",
    "    return best_nid, round(best_score,1)\n",
    "\n",
    "cong_nominees[[\"match_nid\",\"match_score\"]] = cong_nominees.apply(\n",
    "    best_match, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a709203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "THRESHOLD = 80\n",
    "matches = cong_nominees[cong_nominees[\"match_score\"] >= THRESHOLD].copy()\n",
    "print(f\"Matched {len(matches)}/{len(cong_nominees)} nominees with score ≥ {THRESHOLD}\")\n",
    "matches.to_csv(INTERIM_DATA_DIR / \"congress_fjc_nominee_matches.csv\", index=False)\n",
    "\n",
    "# Save the cleaned interim datasets for downstream notebooks\n",
    "cong_nominees.to_csv(INTERIM_DATA_DIR / \"congress_nominees_cleaned.csv\", index=False)\n",
    "fjc_judges.to_csv(INTERIM_DATA_DIR / \"fjc_judges_cleaned.csv\", index=False)\n",
    "fjc_service.to_csv(INTERIM_DATA_DIR / \"fjc_service_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 80\n",
    "matches = cong_nominees[cong_nominees[\"match_score\"] >= THRESHOLD].copy()\n",
    "print(f\"Matched {len(matches)}/{len(cong_nominees)} nominees with score ≥ {THRESHOLD}\")\n",
    "\n",
    "# Analyze unmatched records to understand why they didn't match\n",
    "unmatched_df, reason_summary, examples = analyze_match_failures(cong_nominees, THRESHOLD)\n",
    "\n",
    "# Display summary of failure reasons\n",
    "print(\"\\nFailure Reason Summary:\")\n",
    "display(reason_summary)\n",
    "\n",
    "# Display a few examples of each failure type\n",
    "print(\"\\nExample records for each failure type:\")\n",
    "for reason, example_df in examples.items():\n",
    "    print(f\"\\n{reason}:\")\n",
    "    display(example_df)\n",
    "\n",
    "# Save both matched and unmatched datasets for further analysis\n",
    "matches.to_csv(INTERIM_DATA_DIR / \"congress_fjc_nominee_matches.csv\", index=False)\n",
    "unmatched_df.to_csv(INTERIM_DATA_DIR / \"congress_fjc_nominee_unmatched.csv\", index=False)\n",
    "\n",
    "# Save the cleaned interim datasets for downstream notebooks\n",
    "cong_nominees.to_csv(INTERIM_DATA_DIR / \"congress_nominees_cleaned.csv\", index=False)\n",
    "fjc_judges.to_csv(INTERIM_DATA_DIR / \"fjc_judges_cleaned.csv\", index=False)\n",
    "fjc_service.to_csv(INTERIM_DATA_DIR / \"fjc_service_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
