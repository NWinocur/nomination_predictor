{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd428ca2",
   "metadata": {},
   "source": [
    "# Notebook 1 – Data Cleaning, Feature Engineering, & Entity Resolution\n",
    "**Project:** Judicial Vacancy → Nomination/Confirmation Pipeline\n",
    "\n",
    "*Initial draft generated via ChatGPT model o3 on 2025-07-12T02:40:38.399372Z*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stderr, format=\"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{function}</cyan> - <level>{message}</level>\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667b06c6",
   "metadata": {},
   "source": [
    "## Load dataframes from Raw data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cff186",
   "metadata": {},
   "source": [
    "Start with loading simpler, non-JSON-containing CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d74987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.config import INTERIM_DATA_DIR, RAW_DATA_DIR\n",
    "\n",
    "# load FJC dataframes (and derived seat timeline)\n",
    "fjc_judges = pd.read_csv(RAW_DATA_DIR / \"judges.csv\")\n",
    "fjc_federal_judicial_service = pd.read_csv(RAW_DATA_DIR / \"federal_judicial_service.csv\")\n",
    "fjc_demographics = pd.read_csv(RAW_DATA_DIR / \"demographics.csv\")\n",
    "fjc_education = pd.read_csv(RAW_DATA_DIR / \"education.csv\")\n",
    "fjc_other_federal_judicial_service = pd.read_csv(\n",
    "    RAW_DATA_DIR / \"other_federal_judicial_service.csv\"\n",
    ")\n",
    "fjc_other_nominations_recess = pd.read_csv(RAW_DATA_DIR / \"other_nominations_recess.csv\")\n",
    "fjc_professional_career = pd.read_csv(RAW_DATA_DIR / \"professional_career.csv\")\n",
    "seat_timeline = pd.read_csv(RAW_DATA_DIR / \"seat_timeline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8b36b",
   "metadata": {},
   "source": [
    "Flatten JSON-containing congress DataFrames into separate DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4dd321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.features import flatten_json_dataframe\n",
    "\n",
    "# Load Congress API dataframes\n",
    "cong_nominations_raw = pd.read_csv(RAW_DATA_DIR / \"nominations.csv\")\n",
    "cong_nominees_raw = pd.read_csv(RAW_DATA_DIR / \"nominees.csv\")\n",
    "\n",
    "cong_nominations = flatten_json_dataframe(\n",
    "    df=cong_nominations_raw,\n",
    "    json_col=\"nomination\",  # column containing the JSON data\n",
    "    max_list_index=10,      # maximum number of list items to extract\n",
    "    separator=\"_\"           # separator for nested keys\n",
    ")\n",
    "\n",
    "cong_nominees= flatten_json_dataframe(\n",
    "    df=cong_nominees_raw,\n",
    "    json_col=\"nominee\",\n",
    "    max_list_index=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9765e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes into a single dictionary for bulk operations\n",
    "# Start with FJC dataframes\n",
    "dfs = {\n",
    "    # FJC dataframes\n",
    "    \"fjc_judges\": fjc_judges,\n",
    "    \"fjc_federal_judicial_service\": fjc_federal_judicial_service,\n",
    "    \"fjc_demographics\": fjc_demographics,\n",
    "    \"fjc_education\": fjc_education,\n",
    "    \"fjc_other_federal_judicial_service\": fjc_other_federal_judicial_service,\n",
    "    \"fjc_other_nominations_recess\": fjc_other_nominations_recess,\n",
    "    \"fjc_professional_career\": fjc_professional_career,\n",
    "    \"seat_timeline\": seat_timeline,\n",
    "    \n",
    "    # Congress dataframes\n",
    "    \"cong_nominations\": cong_nominations,\n",
    "    \"cong_nominees\": cong_nominees,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of available dataframes\n",
    "print(\"Available dataframes:\")\n",
    "for name, df in dfs.items():\n",
    "    print(f\"- {name}: {len(df)} rows × {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9682d66f",
   "metadata": {},
   "source": [
    "#### Quick peek at all loaded dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Checking for general shape and first handfuls of rows\")\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name:<35} → {df.shape}\")\n",
    "    print(df.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Checking for null values\")\n",
    "    \n",
    "for name, df in dfs.items():\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f541a22",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a3d80",
   "metadata": {},
   "source": [
    "### Normalize column names for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0828397",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Column Names Before ===\")\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name:<35} → {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01227ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call features.py's normalize_columns function on all DataFrames in dfs, and strip leading and trailing whitespace in all strings\n",
    "from nomination_predictor.features import normalize_dataframe_columns\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    df = normalize_dataframe_columns(df)\n",
    "    df = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    dfs[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b405378",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Column Names After ===\")\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name:<35} → {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a34e1e1",
   "metadata": {},
   "source": [
    "### Left-merge nominees table onto nominations table\n",
    "This will make the cong_noms dataframe we'll use for most of our congress data operations below in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.features import merge_nominees_onto_nominations\n",
    "\n",
    "try:\n",
    "    # Assuming cong_nominations and cong_nominees dataframes are already loaded\n",
    "    cong_noms = merge_nominees_onto_nominations(dfs[\"cong_nominations\"], dfs[\"cong_nominees\"])\n",
    "    \n",
    "    # Show sample of the merged dataframe\n",
    "    display(cong_noms.head())\n",
    "    \n",
    "    # Report on the merge results\n",
    "    logger.info(f\"Original nominations shape: {cong_nominations.shape}\")\n",
    "    logger.info(f\"Original nominees shape: {cong_nominees.shape}\")\n",
    "    logger.info(f\"Merged dataframe shape: {cong_noms.shape}\")\n",
    "    \n",
    "    dfs[\"cong_noms\"] = cong_noms\n",
    "    \n",
    "except NameError:\n",
    "    logger.error(\"Required dataframes (cong_nominations, cong_nominees) are not defined\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in merge process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514c1e9",
   "metadata": {},
   "source": [
    "### Drop rows whose congressional citations end in -0\n",
    "All of these I've seen either:\n",
    "\n",
    "- lack strictly-necessary information such as nomination & confirmation dates,\n",
    "- lack helpful information such as the person's name, or \n",
    "- whatever little information they do have indicates it's not for a position as a judge (e.g. for secretary of defense, assistant secretary to something-or-other-, etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.features import filter_dash_zero_citations\n",
    "\n",
    "dfs[\"cong_noms\"] = filter_dash_zero_citations(dfs[\"cong_noms\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24052def",
   "metadata": {},
   "source": [
    "### Drop non-judge nominations based on position title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-judicial nominations using the function from features.py\n",
    "from nomination_predictor.features import filter_non_judicial_nominations\n",
    "\n",
    "# Define non-judicial titles to filter out\n",
    "non_judicial_titles = [\n",
    "    \"Attorney\", \"Board\", \"Commission\", \"Director\", \"Marshal\",\n",
    "    \"Assistant\", \"Representative\", \"Secretary of\", \"Member of\"\n",
    "]\n",
    "\n",
    "dfs[\"cong_noms\"] = filter_non_judicial_nominations(dfs[\"cong_noms\"], non_judicial_titles=non_judicial_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83af858",
   "metadata": {},
   "source": [
    "## Few new columns from straightforwardly-parsable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.name_matching import fill_vacancy_reason_column\n",
    "\n",
    "dfs[\"cong_noms\"] = fill_vacancy_reason_column(dfs[\"cong_noms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values from predecessor column\n",
    "from nomination_predictor.name_matching import fill_predecessor_column\n",
    "\n",
    "dfs[\"cong_noms\"] = fill_predecessor_column(dfs[\"cong_noms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee74fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column in dfs[\"fjc_federal_judicial_service\"] titled \"fjc_biography_url\"\n",
    "# whose contents are simply the string \"http://www.fjc.gov/node/\" concatenated before whatever integer # can be read from \n",
    "# that same row's \"nid\" column (or empty string if nid is not an integer)\n",
    "\n",
    "svc = dfs[\"fjc_federal_judicial_service\"]\n",
    "\n",
    "svc[\"fjc_biography_url\"] = (\n",
    "    \"http://www.fjc.gov/node/\" +\n",
    "    pd.to_numeric(svc[\"nid\"], errors=\"coerce\")     # turn non-ints into NaN\n",
    "      .dropna()                                    # keep only numeric nids\n",
    "      .astype(int)                                 # cast to int for clean string\n",
    "      .astype(str)   \n",
    ")\n",
    "dfs[\"fjc_federal_judicial_service\"] = svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb293a",
   "metadata": {},
   "source": [
    "## Not yet implemented: Merge only the useful columns of the \"other federal judicial service\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb521ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-merges from dfs[\"fjc_other_federal_judicial_service\"] onto dfs[\"fjc_federal_judicial_service\"], but from the former's columns, doesn't left merge all and keep all of them; does the following:\n",
    "# in the \"other service\" dataframe, prior to left-merging:\n",
    "#   drop/ignore all of the columns whose column names stat with \"unnamed_\"\n",
    "#   ignore column \"judge_name\"\n",
    "#   rename column named \"type\" to \"other_federal_judicial_service_type\"\n",
    "#   rename column named \"sequence\" to \"other_federal_judicial_service_sequence\"\n",
    "#   rename column named \"other_federal_judicial_service\" to \"other_federal_judicial_service_description\"\n",
    "\n",
    "#   adds column named \"other_federal_judicial_service_start_date\" and \"other_federal_judicial_service_end_date\" from \"other_federal_judicial_service_description\"...\n",
    "# by the time I started looking at how to handle year-parsing, and consider the year-spans in light of the sequence number column in this dataframe, I decided it was higher priority to work on other aspects of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70a9a6",
   "metadata": {},
   "source": [
    "#### Merge the \"Other Nominations\" dataframe\n",
    "In theory this should get us the fjc's perspective on more nominees who didn't get confirmed.  \n",
    "\n",
    "In practice my runs of name-matching didn't find any unambiguous matches from this dataframe to the congress one, so I put this on hold to try another day, maybe after seeing whether the additional data would help or whether something had to be fixed/improved about the name matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33742625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-merges from dfs[\"fjc_other_nominations_recess\"] onto dfs[\"fjc_federal_judicial_service\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b269eea",
   "metadata": {},
   "source": [
    "### Convert date strings to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01904b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for any columns which contain certain keywords in their column name and contain string values, convert from string to datetime\n",
    "datetime_related_keywords = (\"date\", \"year\", \"month\")\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    for col in df.columns:\n",
    "        if any(keyword in col for keyword in datetime_related_keywords) and df[col].dtype == \"object\":\n",
    "            logger.info(f\"Converting {col} to datetime for {name}\")\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb8848",
   "metadata": {},
   "source": [
    "### Normalize all string values to make matching them later easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.name_matching import normalize_text\n",
    "\n",
    "keywords_which_denote_string_columns_to_normalize = (\"court\", \"circuit\", \"district\", \"description\", \"name\")\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    for col in df.columns:\n",
    "        if any(keyword in col.casefold() for keyword in keywords_which_denote_string_columns_to_normalize) and df[col].dtype == object:\n",
    "            logger.info(F\"Normalizing all values within column named {col} in {name}\")\n",
    "            df[col] = df[col].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5071ca",
   "metadata": {},
   "source": [
    "### Count and display unique values under each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2df09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display counts of unique values in DataFrame columns:\n",
    "for name, df in dfs.items():\n",
    "    for col in sorted(df.columns):\n",
    "     print(f\"{name} - {col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558daca8",
   "metadata": {},
   "source": [
    "## Name-matching FJC judges to Congress.gov nominees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615091a8",
   "metadata": {},
   "source": [
    "### For confirmed judges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25634a69",
   "metadata": {},
   "source": [
    "#### Supplementing with additional columns to aid matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"full_name_concatenated\" column to the fjc_federal_judicial_service dataframe which is composed by flipping its judge_name column values \n",
    "# from \"lastname, firstname middleNameOrMiddleInitial (, optional comma and suffix)\" to \"firstname lastname middle suffix\"\n",
    "from nomination_predictor.features import \\\n",
    "    convert_judge_name_format_from_last_comma_first_to_first_then_last\n",
    "\n",
    "try:\n",
    "    dfs[\"fjc_federal_judicial_service\"][\"full_name_concatenated\"] = dfs[\"fjc_federal_judicial_service\"][\"judge_name\"].apply(convert_judge_name_format_from_last_comma_first_to_first_then_last)\n",
    "    \n",
    "    # Show some examples to verify the conversion\n",
    "    sample = dfs[\"fjc_federal_judicial_service\"][['judge_name', 'full_name_concatenated']].head(10)\n",
    "    display(sample)\n",
    "    \n",
    "    # Count null values to check for any conversion failures\n",
    "    null_count = dfs[\"fjc_federal_judicial_service\"][\"full_name_concatenated\"].isna().sum()\n",
    "    empty_count = (dfs[\"fjc_federal_judicial_service\"][\"full_name_concatenated\"] == '').sum()\n",
    "    \n",
    "    if null_count > 0 or empty_count > 0:\n",
    "        logger.warning(f\"Found {null_count} null values and {empty_count} empty strings in the converted names.\")\n",
    "        \n",
    "    logger.info(f\"Successfully added 'full_name_concatenated' column to fjc_federal_judicial_service dataframe with {len(dfs[\"fjc_federal_judicial_service\"])}) entries.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error creating full_name_concatenated column: {e}\")\n",
    "    # If there's an error, display the first few rows of fjc_federal_judicial_service to help diagnose\n",
    "    logger.info(\"\\nSample of fjc_federal_judicial_service dataframe:\")\n",
    "    display(dfs[\"fjc_federal_judicial_service\"].head(3))\n",
    "    logger.info(f\"Columns available: {dfs[\"fjc_federal_judicial_service\"].columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"full_name_from_description\" and a \"location_of_origin_from_description\" columns to the dfs[\"cong_noms\"] dataframe which regex-captures the first segments of the same dfs[\"cong_noms\"] dataframe row's \"description\" string, \n",
    "# i.e. captures name before the first appearances of the phrases \", of \" or \", of the \"\n",
    "# and captures location from the second segment of the same dfs[\"cong_noms\"] dataframe row's \"description\" string\n",
    "# i.e. captures between the above-seen phrase \", of \" or \", of the \" through to the phrase \", to be \"\n",
    "# examples: \n",
    "# melissa damian, of florida, to be ...  gets captured into those new columns as \"melissa damian\" and \"florida\"\n",
    "# nicole g. bernerr of maryland, to be united... gets captured into those new columns as \"nicole g. bernerr\" and \"maryland\"\n",
    "# kirk edward sherriff, of california, to be united... gets captured into those new columns as \"kirk edward sherriff\" and \"california\"\n",
    "# sherri malloy beatty-arthur, of the district of columbia, for... gets captured into those new columns as \"sherri malloy beatty-arthur\" and \"district of columbia\"\n",
    "\n",
    "# Extract full_name_from_description and location_of_origin_from_description from description field\n",
    "from nomination_predictor.features import extract_name_and_location_columns\n",
    "\n",
    "# Apply the extraction function to cong_noms dataframe\n",
    "if 'cong_noms' in dfs:\n",
    "    dfs['cong_noms'] = extract_name_and_location_columns(dfs['cong_noms'])\n",
    "    \n",
    "    # Display sample results to verify extraction\n",
    "    sample_cols = ['description', 'full_name_from_description', 'location_of_origin_from_description']\n",
    "    display(dfs['cong_noms'][sample_cols].head(10))\n",
    "    \n",
    "    # Report extraction statistics\n",
    "    total_rows = len(dfs['cong_noms'])\n",
    "    name_filled = dfs['cong_noms']['full_name_from_description'].notna().sum()\n",
    "    location_filled = dfs['cong_noms']['location_of_origin_from_description'].notna().sum()\n",
    "    \n",
    "    logger.info(f\"Extracted names for {name_filled}/{total_rows} records ({name_filled/total_rows:.1%})\")\n",
    "    logger.info(f\"Extracted locations for {location_filled}/{total_rows} records ({location_filled/total_rows:.1%})\")\n",
    "else:\n",
    "    logger.error(\"Error: 'cong_noms' dataframe not found in dfs dictionary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978463f",
   "metadata": {},
   "source": [
    "#### Performing the matching operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.name_matching import perform_exact_name_matching\n",
    "\n",
    "results_of_name_matching_to_bridge_nids_to_congress_dataframe_indices= perform_exact_name_matching(\n",
    "    congress_df=dfs[\"cong_noms\"],\n",
    "    fjc_df=dfs[\"fjc_federal_judicial_service\"],\n",
    "    congress_name_col=\"full_name_from_description\",\n",
    "    fjc_name_col=\"judge_name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e68516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "results_of_name_matching_to_bridge_nids_to_congress_dataframe_indices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db338ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only *unambiguous* pairs\n",
    "nid_map = (\n",
    "    results_of_name_matching_to_bridge_nids_to_congress_dataframe_indices[~results_of_name_matching_to_bridge_nids_to_congress_dataframe_indices[\"ambiguous\"]]        # drop rows still ambiguous\n",
    "      .set_index(\"congress_index\")[\"nid\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at long last, we have a way to bridge the gap between the congress.gov data and the fjc data\n",
    "\n",
    "# we can now use the nid_map to add the nid column to the congress.gov data\n",
    "dfs[\"cong_noms\"][\"nid\"] = dfs[\"cong_noms\"].index.to_series().map(nid_map)\n",
    "cong_noms = dfs[\"cong_noms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d009e2f2",
   "metadata": {},
   "source": [
    "### For unconfirmed judges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2d2b1",
   "metadata": {},
   "source": [
    "In practice, given the dataframes as I've got them as of typing this, this section doesn't find any remaining unconfirmed judges to match.\n",
    "\n",
    "What this section _did_ accomplish was showing me that the presence of diacritical marks such as \"ñ\" or \"é\" in names was misleading the matching process.\n",
    "\n",
    "Discovering and addressing that in much-earlier data-normalizing cells led to getting more matches in our confirmed-judges-matching notebook section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa9c27",
   "metadata": {},
   "source": [
    "#### Supplementing with additional columns to aid matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.name_matching import prep_fjc_other\n",
    "\n",
    "dfs[\"fjc_other_nominations_recess\"] = prep_fjc_other(fjc_other_df=dfs[\"fjc_other_nominations_recess\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fjc_other_supplemented =dfs[\"fjc_other_nominations_recess\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3e3e2",
   "metadata": {},
   "source": [
    "#### Performing the matching operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomination_predictor.features import link_unconfirmed_nominations\n",
    "\n",
    "dfs[\"cong_noms\"] = link_unconfirmed_nominations(dfs[\"cong_noms\"], dfs[\"fjc_other_nominations_recess\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afcfcbf",
   "metadata": {},
   "source": [
    "## Combining the rest of the FJC data now that our congress dataframe has been enriched with FJC nid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7daa8b",
   "metadata": {},
   "source": [
    "### Handling nominees' education and job history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74656c7d",
   "metadata": {},
   "source": [
    "Before we combine FJC data, we have to consider whether/how to handle judges' education, job history, age, ABA rating, etc.  Most/all of the data in the \"demographics\" dataframe is unchanging over time, but that's very much _not_ true of the other dataframes.\n",
    "\n",
    "The simplest way to handle it would be to left-merge on \"nid\" and only take the most recently-dated row, or row with the highest sequence number.  In most cases this would likely land on keeping the most prestigious degree or job.\n",
    "\n",
    "However, it is entirely likely a judge's education or job history has changed substantially since their first nomination, and affected their qualifications for each later nomination.\n",
    "\n",
    "All of these indicate to me that it's worth merging onto each row that judge's position, education, etc., not as of the most recent records available, but instead _as of when they were nominated._\n",
    "\n",
    "That means we can't do a too-simple left-join of all of our FJC data.  Instead, now that we've done the step of matching NIDs to congress' data on nominations, we can use the \"received date\" for each congress citation as a cutoff date for when we lookup education and job records by \"nid\" -- so we can avoid mistakenly linking to a citation any employment & job records dated after that cutoff date.\n",
    "\n",
    "Thankfully we do have the school, degree, and degree_year in the education record, for both their bachelors and their masters and their associate degree(s) and LLB and J.D. etc., so we can look that up.  The education dataframe even comes with a \"sequence\" number for each education record, which is another indicator of chronological order in addition to degree_year for any given \"nid\" lookup for a judge.\n",
    "\n",
    "Job history is more challenging to deal with because literally every row entry in that dataframe lists it uniquely, but we do have the data available.  My earliest attempts to feature-engineer with it include looking for keywords in it, then creating boolean features for whether they did/didn't have experience in common-phrase-identifiable positions such as \"Private practice\" or \"Attorney general\" or \"Navy\" or \"Army\" etc. Theoretically a parser can look for the year spreads listed there as a rough indicator of amounts of experience gleaned from each professional role & when, but that may be too complicated for me to accomplish by the time I'm first presenting this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8da367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nomination_predictor.time_aware_analysis import merge_congress_fjc\n",
    "\n",
    "# Perform the time-aware merge\n",
    "time_aware_merged_df = merge_congress_fjc(dfs[\"cong_noms\"], dfs[\"fjc_judges\"], dfs[\"fjc_demographics\"],\n",
    "                                                  dfs[\"fjc_education\"], dfs[\"fjc_professional_career\"], dfs[\"fjc_federal_judicial_service\"])\n",
    "display(time_aware_merged_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f387b0",
   "metadata": {},
   "source": [
    "### Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "from nomination_predictor.time_aware_analysis import (\n",
    "    congress_number, congress_session, days_into_current_term,\n",
    "    days_until_next_midterm_election, days_until_next_presidential_election,\n",
    "    fill_missing_appointing_presidents, president_number,\n",
    "    presidential_term_index)\n",
    "\n",
    "df = time_aware_merged_df.copy()\n",
    "df[\"receiveddate\"] = pd.to_datetime(df[\"receiveddate\"])   # ensure datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe70029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# presidency- and elections-timeline-related\n",
    "df[\"pres_term_idx\"]  = df[\"receiveddate\"].apply(presidential_term_index)\n",
    "df[\"days_into_pres_term\"] = df[\"receiveddate\"].apply(days_into_current_term)\n",
    "df[\"days_to_next_pres_election\"] = df[\"receiveddate\"].apply(days_until_next_presidential_election)\n",
    "df[\"days_to_next_midterm_election\"]  = df[\"receiveddate\"].apply(days_until_next_midterm_election)\n",
    "df[\"congress_num\"] = df[\"receiveddate\"].apply(congress_number)\n",
    "df[\"congress_session\"] = df[\"receiveddate\"].apply(congress_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a335ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_missing_appointing_presidents(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75230450",
   "metadata": {},
   "source": [
    "Among the hypotheses is that older judges tend to get approved faster because there's not as much concern they'll live long enough to have as much of a total impact over their time in office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age at nomination\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Reference date for “future” check\n",
    "yesterday = (pd.Timestamp.today().normalize() - pd.Timedelta(days=1))\n",
    "\n",
    "#  Mask rows that have *all three* components\n",
    "complete_date_mask = (\n",
    "    df['birth_day'].notna()  &\n",
    "    df['birth_month'].notna() &\n",
    "    df['birth_year'].notna()\n",
    ")\n",
    "\n",
    "#  Initialise column\n",
    "df['birth_date'] = pd.NaT\n",
    "\n",
    "#  Build datetime only for rows that passed the mask\n",
    "tmp_birth = pd.to_datetime(\n",
    "    {\n",
    "        'year':  df.loc[complete_date_mask, 'birth_year'],\n",
    "        'month': df.loc[complete_date_mask, 'birth_month'],\n",
    "        'day':   df.loc[complete_date_mask, 'birth_day']\n",
    "    },\n",
    "    errors='coerce'           # invalid combos → NaT\n",
    ")\n",
    "\n",
    "# Keep the value only if they were at least \"born yesterday, i.e. ignore misfiled future dates\n",
    "tmp_birth = tmp_birth.where(tmp_birth < yesterday, pd.NaT)\n",
    "\n",
    "df.loc[complete_date_mask, 'birth_date'] = tmp_birth\n",
    "\n",
    "df['birth_date'] = pd.to_datetime(df['birth_date'], errors='coerce')\n",
    "\n",
    "df['age_at_nom'] = (\n",
    "    (df['receiveddate'] - df['birth_date']).dt.days // 365.25\n",
    ").astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify seat level\n",
    "df[\"seat_level\"] = (\n",
    "    df[\"description\"] # we do have court_type_(1), # court_type_(2), etc. columns, but for this coarse an analysis it's simpler and accurate-enough to look through the nomination description\n",
    "      .str.lower()\n",
    "      .str.extract(r\"(supreme|circuit|district|(?<=\\s)tax|international|appeals)\") # insists on whitespace before \"tax\" so we can tell \"tax\" or \"taxation\" etc. are a standalone word\n",
    "      .fillna(\"other\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc23711b",
   "metadata": {},
   "source": [
    "### Not-yet-implemented analyses ideas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partisan mismatch: 1 if president_party != party__who_appointed_predecessor\n",
    "# this would require an additional step of linking predecessor name to nid, and way of looking up when the judge with that nid had been in service, possibly even needing to be a date-and-location-aware analysis\n",
    "\n",
    "#party_map = {47: \"R\", 46: \"D\", 45: \"R\", 44: \"D\", 43: \"R\", 42: \"D\", 41: \"R\"}  # extend list\n",
    "#df[\"pres_party\"] = df[\"receiveddate\"].apply(lambda d: party_map.get(president_number(d), None))\n",
    "#df[\"partisan_mismatch\"] = (\n",
    "#    (df[\"pres_party\"].notna()) &\n",
    "#    (df[\"pres_party\"] != df[\"party_of_appointing_president\"])\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# skipping this one because I think we'd get more and/or richer info out of it if we had a more-successful linkage of the unconfirmed nomination rows between congress and fjc's data\n",
    "# #Count prior failed nominations for this seat_id (if column present)\n",
    "\n",
    "#if \"other_nominations_count\" not in df.columns and \"seat_id\" in df.columns:\n",
    "#    prior_counts = (\n",
    "#        df.groupby(\"seat_id\").cumcount()  # number seen so far for that seat\n",
    "#    )\n",
    "#    df[\"num_prior_failed_noms\"] = prior_counts\n",
    "#\n",
    "#display(df.head())\n",
    "#feature_engineered_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450156d",
   "metadata": {},
   "source": [
    "## Saving interim dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to interim data\n",
    "time_aware_merged_df.to_csv(INTERIM_DATA_DIR / \"merged_time_aware.csv\", index=False)\n",
    "feature_engineered_df.to_csv(\"data/interim/feature_engineered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save extracted tables to interim directory\n",
    "for name, df in dfs.items():\n",
    "    if len(df) > 0:  # Only save non-empty DataFrames\n",
    "        output_path = INTERIM_DATA_DIR / f\"{name}.csv\"\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Saved {len(df)} records to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
