{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b092c37",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from nomination_predictor.config import MODELS_DIR, PROCESSED_DATA_DIR\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PROCESSED_DATA_DIR/\"processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a664c",
   "metadata": {},
   "source": [
    "# Choose features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b090b",
   "metadata": {},
   "source": [
    "## target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4addbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"days_nom_to_conf\"\n",
    "\n",
    "# pick target and drop Y label targets from features\n",
    "y = df[TARGET]\n",
    "X = df.drop(columns=[TARGET, \"days_nom_to_latest_action\"])  # other target saved for later tries at modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2378c",
   "metadata": {},
   "source": [
    "## numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75663fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"actions_count\",\n",
    "    \"age_at_nom_days\",\n",
    "    \"birth_year\", \n",
    "    \"committees_count\",\n",
    "    \"congress_num\", \n",
    "    \"days_into_pres_term\",\n",
    "    \"days_nom_to_deceased\",\n",
    "    \"days_to_next_midterm_election\",\n",
    "    \"days_to_next_pres_election\",\n",
    "    \"death_year\", \n",
    "    \"degree_year\", \n",
    "    \"education_sequence\", \n",
    "    \"fed_service_sequence\", \n",
    "    \"highest_degree_level\",\n",
    "    \"professional_career_sequence\",\n",
    "    \"record_vote_number\",   \n",
    "    \"service_as_chief_judge,_begin\", \n",
    "    \"service_as_chief_judge,_end\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6168585",
   "metadata": {},
   "source": [
    "# boolean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_features = [\n",
    "    \"pres_term_is_latter_term\", \n",
    "    \"statute_authorized_new_seat_bool\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2bbf16",
   "metadata": {},
   "source": [
    "# categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69674cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features  = [\n",
    "    \"aba_rating\", \n",
    "    \"appointing_president\",\n",
    "    \"congress_session\",\n",
    "    \"court_type\",\n",
    "    \"seat_level\", \n",
    "    \"birth_state\",\n",
    "    \"latestaction_is_div_opp_house\",\n",
    "    \"latestaction_is_div_opp_senate\",\n",
    "    \"latestaction_is_fully_div\",\n",
    "    \"latestaction_is_unified\",\n",
    "    \"nominees_0_organization\",\n",
    "    \"nominees_0_state\",\n",
    "    \"party_of_appointing_president\",\n",
    "    \"race_or_ethnicity\",\n",
    "    \"school\",\n",
    "    \"seat_id_letters_only\",\n",
    "    \"senate_vote_type\",\n",
    "    \"vacancy_reason\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec7c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All features are unique across feature type lists\n",
      "ℹ️ Total unique features: 38\n"
     ]
    }
   ],
   "source": [
    "def validate_feature_lists(numeric_features, boolean_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Validates that there are no duplicate features across the different feature type lists.\n",
    "    \n",
    "    Args:\n",
    "        numeric_features (list): List of numeric feature names\n",
    "        boolean_features (list): List of boolean feature names\n",
    "        categorical_features (list): List of categorical feature names\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if there are no duplicates, False otherwise\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    from collections import Counter\n",
    "\n",
    "    # Combine all features\n",
    "    all_features = list(itertools.chain(numeric_features, boolean_features, categorical_features))\n",
    "    \n",
    "    # Count occurrences of each feature\n",
    "    feature_counts = Counter(all_features)\n",
    "    \n",
    "    # Find duplicates\n",
    "    duplicates = [feature for feature, count in feature_counts.items() if count > 1]\n",
    "    \n",
    "    if duplicates:\n",
    "        print(\"⚠️ DUPLICATE FEATURES DETECTED:\")\n",
    "        for dup in duplicates:\n",
    "            print(f\"  - '{dup}' appears in multiple feature lists:\")\n",
    "            if dup in numeric_features:\n",
    "                print(\"    • numeric_features\")\n",
    "            if dup in boolean_features:\n",
    "                print(\"    • boolean_features\")\n",
    "            if dup in categorical_features:\n",
    "                print(\"    • categorical_features\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"✅ All features are unique across feature type lists\")\n",
    "        \n",
    "        # Additionally, check total coverage\n",
    "        all_features_set = set(all_features)\n",
    "        if not all_features_set:\n",
    "            print(\"⚠️ WARNING: No features specified in any list\")\n",
    "        else:\n",
    "            print(f\"ℹ️ Total unique features: {len(all_features_set)}\")\n",
    "            \n",
    "        return True\n",
    "\n",
    "# Usage:\n",
    "are_features_valid = validate_feature_lists(numeric_features, boolean_features, categorical_features)\n",
    "\n",
    "if not are_features_valid:\n",
    "    raise ValueError(\"Feature lists contain duplicates. Please fix before continuing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = [\n",
    "    c for c in df.select_dtypes(\"number\").columns\n",
    "    if c not in {TARGET}\n",
    "]\n",
    "\n",
    "df_model = df[df[TARGET].notna()].copy()\n",
    "X = df_model[boolean_features + categorical_features + numeric_features]\n",
    "y = df_model[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=df_model[\"seat_level\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d6351",
   "metadata": {},
   "source": [
    "# Model Selection, Training, and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f304ff9",
   "metadata": {},
   "source": [
    "##  Preprocessing pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a511553",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29475c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressXGBRegressor(XGBRegressor):\n",
    "    \"\"\"Wrapper to be able to get a progress bar\"\"\"\n",
    "    def fit(self, X, y, *args, **kwargs):\n",
    "        # Print start message\n",
    "        logger.info(f\"Starting XGBoost training with {self.n_estimators} trees...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Fit the model\n",
    "        result = super().fit(X, y, *args, **kwargs)\n",
    "        \n",
    "        # Print completion message with timing\n",
    "        elapsed = time.time() - start_time\n",
    "        logger.info(f\"XGBoost training completed in {elapsed:.2f} seconds\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline with preprocessing and model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', ProgressXGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        verbosity=1,  # This provides some built-in progress logging\n",
    "        # Add other XGBoost parameters as needed\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a227ec69",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 13:57:22.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mTraining model on 1129 samples, 38 features\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2856c186bf64dac92a394b007c5bb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Pipeline:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 13:57:22.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mStarting XGBoost training with 300 trees...\u001b[0m\n",
      "\u001b[32m2025-07-16 13:57:33.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mXGBoost training completed in 10.31 seconds\u001b[0m\n",
      "\u001b[32m2025-07-16 13:57:33.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mModel training completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the model with a simple progress indicator\n",
    "logger.info(f\"Training model on {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "with tqdm(total=1, desc=\"Training Pipeline\") as pbar:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    pbar.update(1)\n",
    "logger.info(\"Model training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae547f40",
   "metadata": {},
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163d052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 13:57:33.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mModel evaluation - MAE: 40.12, R²: 0.4474\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "logger.info(f\"Model evaluation - MAE: {mae:.2f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f7bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:00:41.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mModel evaluation - MAE: 40.12, R²: 0.4474\u001b[0m\n",
      "\n",
      "===== Mean Absolute Error (MAE): 40.12 =====\n",
      "📊 GOOD: The model's predictions are typically within 60 days of the actual confirmation time.\n",
      "🔍 TAKEAWAY: The model provides valuable insights but has moderate error margins.\n",
      "\n",
      "===== R² Score: 0.4474 =====\n",
      "📊 FAIR: The model explains between 30-50% of the variance in confirmation times.\n",
      "🔍 TAKEAWAY: The model identifies some patterns but misses many important factors.\n",
      "\n",
      "===== Interpretation in Context =====\n",
      "• The average nomination takes 111 days to confirm\n",
      "• With a standard deviation of 85 days\n",
      "• Our model's error (MAE) is 40 days, which is 47% of the standard deviation\n",
      "• This means our model outperforms a baseline model that always predicts the average\n",
      "\n",
      "===== Recommended Next Steps =====\n",
      "1. Tune hyperparameters to optimize model performance\n",
      "2. Explore feature importance to understand key drivers\n",
      "3. Consider ensemble methods to improve predictions\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Basic log of results\n",
    "logger.info(f\"Model evaluation - MAE: {mae:.2f}, R²: {r2:.4f}\")\n",
    "\n",
    "# Detailed interpretation of MAE\n",
    "print(f\"\\n===== Mean Absolute Error (MAE): {mae:.2f} =====\")\n",
    "if mae < 30:\n",
    "    print(\"📊 EXCELLENT: The model's predictions are typically within 30 days of the actual confirmation time.\")\n",
    "    print(\"🔍 TAKEAWAY: The model has high practical utility for predicting confirmation timelines.\")\n",
    "elif mae < 60:\n",
    "    print(\"📊 GOOD: The model's predictions are typically within 60 days of the actual confirmation time.\")\n",
    "    print(\"🔍 TAKEAWAY: The model provides valuable insights but has moderate error margins.\")\n",
    "elif mae < 90:\n",
    "    print(\"📊 FAIR: The model's predictions are typically within 90 days of the actual confirmation time.\")\n",
    "    print(\"🔍 TAKEAWAY: The model offers directional guidance but with substantial uncertainty.\")\n",
    "else:\n",
    "    print(\"📊 NEEDS IMPROVEMENT: The model's predictions have large error margins exceeding 90 days.\")\n",
    "    print(\"🔍 TAKEAWAY: Consider feature engineering, hyperparameter tuning, or alternative algorithms.\")\n",
    "\n",
    "# Detailed interpretation of R²\n",
    "print(f\"\\n===== R² Score: {r2:.4f} =====\")\n",
    "if r2 > 0.7:\n",
    "    print(\"📊 STRONG: The model explains more than 70% of the variance in confirmation times.\")\n",
    "    print(\"🔍 TAKEAWAY: The model captures most of the systematic patterns in the data.\")\n",
    "elif r2 > 0.5:\n",
    "    print(\"📊 MODERATE: The model explains between 50-70% of the variance in confirmation times.\")\n",
    "    print(\"🔍 TAKEAWAY: The model captures significant patterns but misses some factors.\")\n",
    "elif r2 > 0.3:\n",
    "    print(\"📊 FAIR: The model explains between 30-50% of the variance in confirmation times.\")\n",
    "    print(\"🔍 TAKEAWAY: The model identifies some patterns but misses many important factors.\")\n",
    "else:\n",
    "    print(\"📊 WEAK: The model explains less than 30% of the variance in confirmation times.\")\n",
    "    print(\"🔍 TAKEAWAY: The model has limited predictive power, consider revisiting features or methodology.\")\n",
    "\n",
    "# Context relative to problem domain\n",
    "print(\"\\n===== Interpretation in Context =====\")\n",
    "print(f\"• The average nomination takes {y_train.mean():.0f} days to confirm\")\n",
    "print(f\"• With a standard deviation of {y_train.std():.0f} days\")\n",
    "print(f\"• Our model's error (MAE) is {mae:.0f} days, which is {(mae/y_train.std()*100):.0f}% of the standard deviation\")\n",
    "print(f\"• This means our model {('outperforms' if r2 > 0 else 'underperforms')} a baseline model that always predicts the average\")\n",
    "\n",
    "# Actionable next steps\n",
    "print(\"\\n===== Recommended Next Steps =====\")\n",
    "if r2 < 0.3 or mae > 90:\n",
    "    print(\"1. Consider feature engineering to identify more predictive variables\")\n",
    "    print(\"2. Try different algorithms (Random Forest, Neural Networks)\")\n",
    "    print(\"3. Collect additional data or domain-specific features\")\n",
    "elif r2 < 0.6:\n",
    "    print(\"1. Tune hyperparameters to optimize model performance\")\n",
    "    print(\"2. Explore feature importance to understand key drivers\")\n",
    "    print(\"3. Consider ensemble methods to improve predictions\")\n",
    "else:\n",
    "    print(\"1. Focus on model interpretability to understand key drivers\")\n",
    "    print(\"2. Validate on additional test data to ensure generalizability\")\n",
    "    print(\"3. Consider deploying the model for practical use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6567dd",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc173c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_with_metadata(model, file_prefix, metadata=None):\n",
    "    \"\"\"Save model with timestamp and metadata\"\"\"\n",
    "    import os\n",
    "    import pickle\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Create models directory if it doesn't exist\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    \n",
    "    # Create a sanitized timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    \n",
    "    # Generate filename\n",
    "    filename = MODELS_DIR/f\"{file_prefix}_{timestamp}.pkl\"\n",
    "    \n",
    "    # Default metadata if none provided\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    \n",
    "    # Add standard metadata\n",
    "    metadata.update({\n",
    "        'timestamp': timestamp,\n",
    "        'features': X_train.columns.tolist(),\n",
    "        'n_features': X_train.shape[1],\n",
    "        'metrics': {\n",
    "            'mae': float(mae),\n",
    "            'r2': float(r2)\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Save model and metadata\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump({'model': pipeline, 'metadata': metadata}, f)\n",
    "    \n",
    "    logger.info(f\"Model saved to {filename} with metadata\")\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b63db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:06:19.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model_with_metadata\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mModel saved to /home/wsl2ubuntuuser/nomination_predictor/models/xgboost_regression_2025-07-16_140619.pkl with metadata\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_file = save_model_with_metadata(\n",
    "    pipeline, \n",
    "    \"xgboost_regression\",\n",
    "    metadata={\n",
    "        'description': 'XGBoost regression model for nomination confirmation time prediction',\n",
    "        'parameters': {\n",
    "            'n_estimators': 300,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 6\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
