{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b092c37",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2280e74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:18.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mProject root: /home/wsl2ubuntuuser/nomination_predictor\u001b[0m\n",
      "\u001b[32m2025-07-16 14:34:18.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mConfiguration loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from nomination_predictor.config import MODELS_DIR, PROCESSED_DATA_DIR\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PROCESSED_DATA_DIR/\"processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a664c",
   "metadata": {},
   "source": [
    "# Choose features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b090b",
   "metadata": {},
   "source": [
    "## target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4addbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"days_nom_to_conf\"\n",
    "\n",
    "# pick target and drop Y label targets from features\n",
    "y = df[TARGET]\n",
    "X = df.drop(columns=[TARGET, \"days_nom_to_latest_action\"])  # other target saved for later tries at modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2378c",
   "metadata": {},
   "source": [
    "## numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75663fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"actions_count\",\n",
    "    \"age_at_nom_days\",\n",
    "    \"birth_year\", \n",
    "    \"committees_count\",\n",
    "    \"congress_num\", \n",
    "    \"days_into_pres_term\",\n",
    "    \"days_nom_to_deceased\",\n",
    "    \"days_to_next_midterm_election\",\n",
    "    \"days_to_next_pres_election\",\n",
    "    \"death_year\", \n",
    "    \"degree_year\", \n",
    "    \"education_sequence\", \n",
    "    \"fed_service_sequence\", \n",
    "    \"highest_degree_level\",\n",
    "    \"professional_career_sequence\",\n",
    "    \"record_vote_number\",   \n",
    "    \"service_as_chief_judge,_begin\", \n",
    "    \"service_as_chief_judge,_end\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6168585",
   "metadata": {},
   "source": [
    "# boolean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_features = [\n",
    "    \"pres_term_is_latter_term\", \n",
    "    \"statute_authorized_new_seat_bool\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2bbf16",
   "metadata": {},
   "source": [
    "# categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69674cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features  = [\n",
    "    \"aba_rating\", \n",
    "    \"appointing_president\",\n",
    "    \"congress_session\",\n",
    "    \"court_type\",\n",
    "    \"seat_level\", \n",
    "    \"birth_state\",\n",
    "    \"latestaction_is_div_opp_house\",\n",
    "    \"latestaction_is_div_opp_senate\",\n",
    "    \"latestaction_is_fully_div\",\n",
    "    \"latestaction_is_unified\",\n",
    "    \"nominees_0_organization\",\n",
    "    \"nominees_0_state\",\n",
    "    \"party_of_appointing_president\",\n",
    "    \"race_or_ethnicity\",\n",
    "    \"school\",\n",
    "    \"seat_id_letters_only\",\n",
    "    \"senate_vote_type\",\n",
    "    \"vacancy_reason\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec7c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All features are unique across feature type lists\n",
      "ℹ️ Total unique features: 38\n"
     ]
    }
   ],
   "source": [
    "from nomination_predictor.modeling.train import validate_feature_lists\n",
    "\n",
    "are_features_unique = validate_feature_lists(numeric_features, boolean_features, categorical_features)\n",
    "\n",
    "if not are_features_unique:\n",
    "    raise ValueError(\"Feature lists contain duplicates. Please fix before continuing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = [\n",
    "    c for c in df.select_dtypes(\"number\").columns\n",
    "    if c not in {TARGET}\n",
    "]\n",
    "\n",
    "df_model = df[df[TARGET].notna()].copy()\n",
    "X = df_model[boolean_features + categorical_features + numeric_features]\n",
    "y = df_model[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=df_model[\"seat_level\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d6351",
   "metadata": {},
   "source": [
    "# Model Selection, Training, and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f304ff9",
   "metadata": {},
   "source": [
    "##  Preprocessing pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a511553",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29475c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressXGBRegressor(XGBRegressor):\n",
    "    \"\"\"Wrapper to be able to get a progress bar\"\"\"\n",
    "    def fit(self, X, y, *args, **kwargs):\n",
    "        # Print start message\n",
    "        logger.info(f\"Starting XGBoost training with {self.n_estimators} trees...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Fit the model\n",
    "        result = super().fit(X, y, *args, **kwargs)\n",
    "        \n",
    "        # Print completion message with timing\n",
    "        elapsed = time.time() - start_time\n",
    "        logger.info(f\"XGBoost training completed in {elapsed:.2f} seconds\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ESTIMATORS = 300\n",
    "LEARNING_RATE = 0.1\n",
    "MAX_DEPTH = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0aecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the pipeline with preprocessing and model\n",
    "pipeline_speedy = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', ProgressXGBRegressor(\n",
    "        n_estimators=NUM_ESTIMATORS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        verbosity=1,  # This provides some built-in progress logging\n",
    "        # Add other XGBoost parameters as needed\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a227ec69",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:19.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mTraining model on 1129 samples, 38 features\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Pipeline:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:19.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mStarting XGBoost training with 300 trees...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Pipeline: 100%|██████████| 1/1 [00:14<00:00, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:33.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mXGBoost training completed in 14.41 seconds\u001b[0m\n",
      "\u001b[32m2025-07-16 14:34:33.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mModel training completed\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nomination_predictor.modeling.train import train_model\n",
    "\n",
    "pipeline = train_model(pipeline_speedy, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae547f40",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163d052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:34.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.predict\u001b[0m:\u001b[36mpredict_model\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mPredicting using model on 283 samples, 38 features\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<00:00, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:34.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.predict\u001b[0m:\u001b[36mpredict_model\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mPrediction completed\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nomination_predictor.modeling.predict import predict_model\n",
    "\n",
    "y_pred = predict_model(pipeline, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb3190f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f7bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:34.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mModel evaluation - MAE: 40.12, R²: 0.4474\u001b[0m\n",
      "\n",
      "===== Mean Absolute Error (MAE): 40.12 =====\n",
      "📊 GOOD: The model's predictions are typically within 60 days of the actual confirmation time.\n",
      "🔍 TAKEAWAY: The model provides valuable insights but has moderate error margins.\n",
      "\n",
      "===== R² Score: 0.4474 =====\n",
      "📊 FAIR: The model explains between 30-50% of the variance in confirmation times.\n",
      "🔍 TAKEAWAY: The model identifies some patterns but misses many important factors.\n",
      "\n",
      "===== Interpretation in Context =====\n",
      "• The average nomination takes 111 days to confirm\n",
      "• With a standard deviation of 85 days\n",
      "• Our model's error (MAE) is 40 days, which is 47% of the standard deviation\n",
      "• This means our model outperforms a baseline model that always predicts the average\n",
      "\n",
      "===== Recommended Next Steps =====\n",
      "1. Tune hyperparameters to optimize model performance\n",
      "2. Explore feature importance to understand key drivers\n",
      "3. Consider ensemble methods to improve predictions\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from nomination_predictor.modeling.predict import interpret_results\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "logger.info(f\"Model evaluation - MAE: {mae:.2f}, R²: {r2:.4f}\")\n",
    "\n",
    "interpret_results(mae, r2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6567dd",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b63db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:34.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36msave_model_with_metadata\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mModel saved to /home/wsl2ubuntuuser/nomination_predictor/models/xgboost_regression_2025-07-16_143434.pkl with metadata\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from nomination_predictor.modeling.train import save_model_with_metadata\n",
    "\n",
    "model_file = save_model_with_metadata(\n",
    "    pipeline, \n",
    "    \"xgboost_regression\",\n",
    "    metadata={\n",
    "        'description': 'XGBoost regression model for nomination confirmation time prediction',\n",
    "        'parameters': {\n",
    "            'n_estimators': NUM_ESTIMATORS,\n",
    "            'learning_rate': LEARNING_RATE,\n",
    "            'max_depth': MAX_DEPTH\n",
    "        }\n",
    "    },\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    mae=mae,\n",
    "    r2=r2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f0323",
   "metadata": {},
   "source": [
    "# Again, but slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e47eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ESTIMATORS_LONGER = NUM_ESTIMATORS *2\n",
    "\n",
    "pipeline_longer = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', ProgressXGBRegressor(\n",
    "        n_estimators=NUM_ESTIMATORS_LONGER,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        verbosity=1,  # This provides some built-in progress logging\n",
    "        # Add other XGBoost parameters as needed\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d894320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:34.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mTraining model on 1129 samples, 38 features\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Pipeline:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:34.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mStarting XGBoost training with 600 trees...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Pipeline: 100%|██████████| 1/1 [00:22<00:00, 22.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:57.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mXGBoost training completed in 22.51 seconds\u001b[0m\n",
      "\u001b[32m2025-07-16 14:34:57.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mModel training completed\u001b[0m\n",
      "\u001b[32m2025-07-16 14:34:57.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.predict\u001b[0m:\u001b[36mpredict_model\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mPredicting using model on 283 samples, 38 features\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<00:00, 38.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:57.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.predict\u001b[0m:\u001b[36mpredict_model\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mPrediction completed\u001b[0m\n",
      "\u001b[32m2025-07-16 14:34:57.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mModel evaluation - MAE: 40.56, R²: 0.4474\u001b[0m\n",
      "\n",
      "===== Mean Absolute Error (MAE): 40.56 =====\n",
      "📊 GOOD: The model's predictions are typically within 60 days of the actual confirmation time.\n",
      "🔍 TAKEAWAY: The model provides valuable insights but has moderate error margins.\n",
      "\n",
      "===== R² Score: 0.4474 =====\n",
      "📊 FAIR: The model explains between 30-50% of the variance in confirmation times.\n",
      "🔍 TAKEAWAY: The model identifies some patterns but misses many important factors.\n",
      "\n",
      "===== Interpretation in Context =====\n",
      "• The average nomination takes 111 days to confirm\n",
      "• With a standard deviation of 85 days\n",
      "• Our model's error (MAE) is 41 days, which is 48% of the standard deviation\n",
      "• This means our model outperforms a baseline model that always predicts the average\n",
      "\n",
      "===== Recommended Next Steps =====\n",
      "1. Tune hyperparameters to optimize model performance\n",
      "2. Explore feature importance to understand key drivers\n",
      "3. Consider ensemble methods to improve predictions\n",
      "\u001b[32m2025-07-16 14:34:57.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36msave_model_with_metadata\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mModel saved to /home/wsl2ubuntuuser/nomination_predictor/models/xgboost_regression_2025-07-16_143457.pkl with metadata\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = train_model(pipeline_longer, X_train, y_train)\n",
    "y_pred = predict_model(pipeline, X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "logger.info(f\"Model evaluation - MAE: {mae:.2f}, R²: {r2:.4f}\")\n",
    "\n",
    "interpret_results(mae, r2, y_train)\n",
    "\n",
    "model_file = save_model_with_metadata(\n",
    "    pipeline, \n",
    "    \"xgboost_regression\",\n",
    "    metadata={\n",
    "        'description': 'XGBoost regression model for nomination confirmation time prediction',\n",
    "        'parameters': {\n",
    "            'n_estimators': NUM_ESTIMATORS_LONGER,\n",
    "            'learning_rate': LEARNING_RATE,\n",
    "            'max_depth': MAX_DEPTH\n",
    "        }\n",
    "    },\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    mae=mae,\n",
    "    r2=r2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeafa084",
   "metadata": {},
   "source": [
    "# Again, with more patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ESTIMATORS_LONGEST = NUM_ESTIMATORS * 4\n",
    "pipeline_longest = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', ProgressXGBRegressor(\n",
    "        n_estimators=NUM_ESTIMATORS_LONGEST,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        verbosity=1,  # This provides some built-in progress logging\n",
    "        # Add other XGBoost parameters as needed\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bd7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:57.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mTraining model on 1129 samples, 38 features\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Pipeline:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:34:57.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mStarting XGBoost training with 600 trees...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Pipeline: 100%|██████████| 1/1 [00:24<00:00, 24.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:35:21.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mXGBoost training completed in 24.55 seconds\u001b[0m\n",
      "\u001b[32m2025-07-16 14:35:21.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mModel training completed\u001b[0m\n",
      "\u001b[32m2025-07-16 14:35:21.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.predict\u001b[0m:\u001b[36mpredict_model\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mPredicting using model on 283 samples, 38 features\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<00:00, 25.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-16 14:35:21.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.predict\u001b[0m:\u001b[36mpredict_model\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mPrediction completed\u001b[0m\n",
      "\u001b[32m2025-07-16 14:35:21.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mModel evaluation - MAE: 40.56, R²: 0.4474\u001b[0m\n",
      "\n",
      "===== Mean Absolute Error (MAE): 40.56 =====\n",
      "📊 GOOD: The model's predictions are typically within 60 days of the actual confirmation time.\n",
      "🔍 TAKEAWAY: The model provides valuable insights but has moderate error margins.\n",
      "\n",
      "===== R² Score: 0.4474 =====\n",
      "📊 FAIR: The model explains between 30-50% of the variance in confirmation times.\n",
      "🔍 TAKEAWAY: The model identifies some patterns but misses many important factors.\n",
      "\n",
      "===== Interpretation in Context =====\n",
      "• The average nomination takes 111 days to confirm\n",
      "• With a standard deviation of 85 days\n",
      "• Our model's error (MAE) is 41 days, which is 48% of the standard deviation\n",
      "• This means our model outperforms a baseline model that always predicts the average\n",
      "\n",
      "===== Recommended Next Steps =====\n",
      "1. Tune hyperparameters to optimize model performance\n",
      "2. Explore feature importance to understand key drivers\n",
      "3. Consider ensemble methods to improve predictions\n",
      "\u001b[32m2025-07-16 14:35:21.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36msave_model_with_metadata\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mModel saved to /home/wsl2ubuntuuser/nomination_predictor/models/xgboost_regression_2025-07-16_143521.pkl with metadata\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = train_model(pipeline_longer, X_train, y_train)\n",
    "y_pred = predict_model(pipeline, X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "logger.info(f\"Model evaluation - MAE: {mae:.2f}, R²: {r2:.4f}\")\n",
    "\n",
    "interpret_results(mae, r2, y_train)\n",
    "\n",
    "model_file = save_model_with_metadata(\n",
    "    pipeline, \n",
    "    \"xgboost_regression\",\n",
    "    metadata={\n",
    "        'description': 'XGBoost regression model for nomination confirmation time prediction',\n",
    "        'parameters': {\n",
    "            'n_estimators': NUM_ESTIMATORS_LONGER,\n",
    "            'learning_rate': LEARNING_RATE,\n",
    "            'max_depth': MAX_DEPTH\n",
    "        }\n",
    "    },\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    mae=mae,\n",
    "    r2=r2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
