{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b092c37",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from nomination_predictor.config import MODELS_DIR, PROCESSED_DATA_DIR\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "DATA_PATH  = Path(PROCESSED_DATA_DIR/\"processed.csv\")\n",
    "MODEL_PATH = Path(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a664c",
   "metadata": {},
   "source": [
    "# Choose features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b090b",
   "metadata": {},
   "source": [
    "## target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4addbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"days_nom_to_conf\"\n",
    "\n",
    "# pick target and drop Y label targets from features\n",
    "y = df[TARGET]\n",
    "X = df.drop(columns=[TARGET, \"days_nom_to_latest_action\"])  # other target saved for later tries at modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2378c",
   "metadata": {},
   "source": [
    "## numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75663fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"age_at_nom_days\", \"days_into_pres_term\", \"days_to_next_pres_election\", \"days_to_next_midterm_election\",\n",
    "    \"congress_num\", \"service_as_chief_judge_begin\", \"service_as_chief_judge,_end\",\n",
    "    \"actions_count\", \"birth_year\", \"degree_year\", \"death_year\", \"record_vote_number\", \"committees_count\", \n",
    "    \"fed_service_sequence\", \"professional_career_sequence\", \"education_sequence\",  \n",
    "   \"highest_degree_level\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6168585",
   "metadata": {},
   "source": [
    "# boolean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = [\n",
    "    \"pres_term_is_latter_term\", \"congress_session\",\n",
    "    \"statute_authorized_new_seat_bool\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2bbf16",
   "metadata": {},
   "source": [
    "# categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69674cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    \"aba_rating\", \n",
    "    \"appointing_president\",\n",
    "    \"congress_session\",\n",
    "    \"court_type\",\n",
    "    \"seat_level\", \n",
    "    \"nominee_birth_state\",\n",
    "    \"latestaction_is_div_opp_house\",\n",
    "    \"latestaction_is_div_opp_senate\",\n",
    "    \"latestaction_is_fully_div\",\n",
    "    \"latestaction_is_unified\",\n",
    "    \"nominees_0_organization\",\n",
    "    \"nominees_0_state\",\n",
    "    \"pres_term_is_latter_term\",\n",
    "    \"race_or_ethnicity\",\n",
    "    \"school\",\n",
    "    \"seat_id_letters_only\",\n",
    "    \"senate_vote_type\",\n",
    "    \"party_of_appointing_president\"\n",
    "    \"vacancy_reason\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = [\n",
    "    c for c in df.select_dtypes(\"number\").columns\n",
    "    if c not in {TARGET}\n",
    "]\n",
    "\n",
    "df_model = df[df[TARGET].notna()].copy()\n",
    "X = df_model[bool_cols + cat_cols + num_cols]\n",
    "y = df_model[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=df_model[\"seat_level\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f304ff9",
   "metadata": {},
   "source": [
    "#  Preprocessing & model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c61376",
   "metadata": {},
   "source": [
    "# training using XGBoost's API\n",
    "\n",
    "Doing it this way to get a less error-prone progress bar vs. when I'd tried using tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fe96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f55f098b67470b949d0be0015b8659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "XGBoost Training:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import tqdm for progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Create a custom callback that works with the current XGBoost API\n",
    "class TqdmProgressCallback(xgb.callback.TrainingCallback):\n",
    "    def __init__(self, n_estimators):\n",
    "        self.pbar = tqdm(total=n_estimators, desc=\"XGBoost Training\")\n",
    "        self.curr_iteration = 0\n",
    "    \n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        # Update progress bar\n",
    "        self.pbar.update(1)\n",
    "        \n",
    "        # Optionally print evaluation metrics every 10 iterations\n",
    "        if epoch % 10 == 0 and evals_log:\n",
    "            message = f\"[{epoch}] \"\n",
    "            for eval_name, metric_dict in evals_log.items():\n",
    "                for metric_name, metric_values in metric_dict.items():\n",
    "                    message += f\"{eval_name}-{metric_name}:{metric_values[-1]:.4f} \"\n",
    "            tqdm.write(message)\n",
    "        \n",
    "        # Return False to continue training\n",
    "        return False\n",
    "    \n",
    "    def __del__(self):\n",
    "        # Clean up progress bar\n",
    "        try:\n",
    "            self.pbar.close()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Create callback instance\n",
    "tqdm_callback = TqdmProgressCallback(n_estimators)\n",
    "\n",
    "# Train with progress bar using native XGBoost API\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=n_estimators,\n",
    "    callbacks=[tqdm_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7109e563",
   "metadata": {},
   "source": [
    "# Prediction with trained model\n",
    "\n",
    "Because I chose to use XGBoost's native API for the sake of getting a progress bar, that means having to use DMatrix instead of the as-is dataframes for prediction, because I'm not just using scikitlearn's wrapper for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da833e97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:latestaction_actiondate: object, nominees_0_organization: object, receiveddate: object, nominees_0_firstname: object, nominees_0_lastname: object, nominees_0_middlename: object, nominees_0_state: object, nominees_0_suffix: object, vacancy_reason: object, full_name_from_description: object, location_of_origin_from_description: object, last_name: object, first_name: object, middle_name: object, suffix: object, birth_city: object, birth_state: object, death_city: object, death_state: object, gender: object, race_or_ethnicity: object, fjc_biography_url: object, degree: object, school: object, professional_career: object, judge_name: object, court_type: object, court_name: object, appointment_title: object, appointing_president: object, party_of_appointing_president: object, aba_rating: object, seat_id: object, statute_authorizing_new_seat: object, nomination_date: object, committee_referral_date: object, hearing_date: object, judiciary_committee_action: object, committee_action_date: object, senate_vote_type: object, confirmation_date: object, commission_date: object, senior_status_date: object, termination: object, termination_date: object, latest_action_taken: object, was_unanimous_decision: object, seat_id_letters_only: object, nominee_parsed_positiontitle: object, birth_date_approx_dt: object, death_date_exact: object, seat_level: object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/data.py:407\u001b[39m, in \u001b[36mpandas_feature_info\u001b[39m\u001b[34m(data, meta, feature_names, feature_types, enable_categorical)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     new_feature_types.append(\u001b[43m_pandas_dtype_mapper\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'object'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert X_test to DMatrix before prediction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dtest = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Now predict\u001b[39;00m\n\u001b[32m      5\u001b[39m pred = model.predict(dtest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/core.py:885\u001b[39m, in \u001b[36mDMatrix.__init__\u001b[39m\u001b[34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[39m\n\u001b[32m    882\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    883\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m handle, feature_names, feature_types = \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    895\u001b[39m \u001b[38;5;28mself\u001b[39m.handle = handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/data.py:1441\u001b[39m, in \u001b[36mdispatch_data_backend\u001b[39m\u001b[34m(data, missing, threads, feature_names, feature_types, enable_categorical, data_split_mode)\u001b[39m\n\u001b[32m   1439\u001b[39m     data = pd.DataFrame(data)\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnthread\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1447\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_cudf_df(data) \u001b[38;5;129;01mor\u001b[39;00m _is_cudf_ser(data):\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_cudf_df(\n\u001b[32m   1452\u001b[39m         data=data,\n\u001b[32m   1453\u001b[39m         missing=missing,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1457\u001b[39m         enable_categorical=enable_categorical,\n\u001b[32m   1458\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/data.py:674\u001b[39m, in \u001b[36m_from_pandas_df\u001b[39m\u001b[34m(data, enable_categorical, missing, nthread, feature_names, feature_types, data_split_mode)\u001b[39m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_pandas_df\u001b[39m(\n\u001b[32m    665\u001b[39m     *,\n\u001b[32m    666\u001b[39m     data: DataFrame,\n\u001b[32m   (...)\u001b[39m\u001b[32m    672\u001b[39m     data_split_mode: DataSplitMode = DataSplitMode.ROW,\n\u001b[32m    673\u001b[39m ) -> DispatchedDataBackendReturnType:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m     df, feature_names, feature_types = \u001b[43m_transform_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    678\u001b[39m     handle = ctypes.c_void_p()\n\u001b[32m    679\u001b[39m     _check_call(\n\u001b[32m    680\u001b[39m         _LIB.XGDMatrixCreateFromColumnar(\n\u001b[32m    681\u001b[39m             df.array_interface(),\n\u001b[32m   (...)\u001b[39m\u001b[32m    686\u001b[39m         )\n\u001b[32m    687\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/data.py:640\u001b[39m, in \u001b[36m_transform_pandas_df\u001b[39m\u001b[34m(data, enable_categorical, feature_names, feature_types, meta)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data.columns) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _matrix_meta:\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataFrame for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot have multiple columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m feature_names, feature_types = \u001b[43mpandas_feature_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    644\u001b[39m arrays = pandas_transform_data(data)\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PandasTransformed(arrays), feature_names, feature_types\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/data.py:409\u001b[39m, in \u001b[36mpandas_feature_info\u001b[39m\u001b[34m(data, meta, feature_names, feature_types, enable_categorical)\u001b[39m\n\u001b[32m    407\u001b[39m             new_feature_types.append(_pandas_dtype_mapper[dtype.name])\n\u001b[32m    408\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m             \u001b[43m_invalid_dataframe_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    412\u001b[39m     feature_types = new_feature_types\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/data.py:372\u001b[39m, in \u001b[36m_invalid_dataframe_dtype\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    370\u001b[39m type_err = \u001b[33m\"\u001b[39m\u001b[33mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:latestaction_actiondate: object, nominees_0_organization: object, receiveddate: object, nominees_0_firstname: object, nominees_0_lastname: object, nominees_0_middlename: object, nominees_0_state: object, nominees_0_suffix: object, vacancy_reason: object, full_name_from_description: object, location_of_origin_from_description: object, last_name: object, first_name: object, middle_name: object, suffix: object, birth_city: object, birth_state: object, death_city: object, death_state: object, gender: object, race_or_ethnicity: object, fjc_biography_url: object, degree: object, school: object, professional_career: object, judge_name: object, court_type: object, court_name: object, appointment_title: object, appointing_president: object, party_of_appointing_president: object, aba_rating: object, seat_id: object, statute_authorizing_new_seat: object, nomination_date: object, committee_referral_date: object, hearing_date: object, judiciary_committee_action: object, committee_action_date: object, senate_vote_type: object, confirmation_date: object, commission_date: object, senior_status_date: object, termination: object, termination_date: object, latest_action_taken: object, was_unanimous_decision: object, seat_id_letters_only: object, nominee_parsed_positiontitle: object, birth_date_approx_dt: object, death_date_exact: object, seat_level: object"
     ]
    }
   ],
   "source": [
    "# Apply the same preprocessing that was used during training\n",
    "X_test_processed = prep_step.transform(X_test)\n",
    "\n",
    "# Create DMatrix with processed features\n",
    "dtest = xgb.DMatrix(X_test_processed)\n",
    "\n",
    "# Now predict\n",
    "pred = model.predict(dtest)\n",
    "print(\"MAE on hold‑out:\", mean_absolute_error(y_test, pred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6567dd",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc173c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def save_model(model, model_name=\"nomination_predictor\", metrics=None):\n",
    "    # Create formatted timestamp (YYYY-MM-DD_HHMMSS)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    \n",
    "    # Create directory for this model version\n",
    "    version_dir = Path(MODELS_DIR) / f\"{model_name}_{timestamp}\"\n",
    "    version_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = version_dir / \"model.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # Save metadata (parameters, performance metrics)\n",
    "    metadata = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"model_type\": type(model).__name__,\n",
    "        \"parameters\": model.get_params() if hasattr(model, \"get_params\") else {},\n",
    "        \"metrics\": metrics or {},\n",
    "        \"python_version\": sys.version,\n",
    "        # Add other relevant info: feature names, etc.\n",
    "    }\n",
    "    \n",
    "    with open(version_dir / \"metadata.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Model saved to {version_dir}\")\n",
    "    return version_dir\n",
    "\n",
    "# Usage:\n",
    "metrics = {\n",
    "    \"rmse\": rmse_score,\n",
    "    \"r2\": r2_score,\n",
    "    \"mae\": mae_score\n",
    "}\n",
    "\n",
    "save_model(xgb, metrics=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
