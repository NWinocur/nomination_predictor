{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b092c37",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280e74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-18 14:35:32.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mProject root: /home/wsl2ubuntuuser/nomination_predictor\u001b[0m\n",
      "\u001b[32m2025-07-18 14:35:32.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mConfiguration loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from nomination_predictor.config import MODELS_DIR, PROCESSED_DATA_DIR\n",
    "from nomination_predictor.modeling.predict import (compare_models,\n",
    "                                                   evaluate_and_report_model,\n",
    "                                                   train_and_evaluate_model)\n",
    "from nomination_predictor.modeling.train import save_model_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PROCESSED_DATA_DIR/\"processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52963229",
   "metadata": {},
   "source": [
    "# Verify GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf384ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 XGBoost version: 3.0.2\n",
      "✅ GPU detected:\n",
      "  🔹 NVIDIA GeForce RTX 3070, 8192 MiB\n",
      "  🔹 NVIDIA GeForce RTX 2060, 6144 MiB\n",
      "✅ XGBoost GPU support confirmed with current syntax!\n"
     ]
    }
   ],
   "source": [
    "# Verify current GPU setup\n",
    "import subprocess\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "print(f\"📦 XGBoost version: {xgb.__version__}\")\n",
    "\n",
    "# Test GPU availability\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ GPU detected:\")\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            print(f\"  🔹 {line}\")\n",
    "    else:\n",
    "        print(\"❌ nvidia-smi failed\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ nvidia-smi not found\")\n",
    "\n",
    "# Test XGBoost GPU support\n",
    "try:\n",
    "    test_model = xgb.XGBRegressor(tree_method=\"hist\", device=\"cuda\")\n",
    "    print(\"✅ XGBoost GPU support confirmed with current syntax!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ XGBoost GPU issue: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a664c",
   "metadata": {},
   "source": [
    "# Choose features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b090b",
   "metadata": {},
   "source": [
    "## target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4addbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"days_nom_to_conf\"\n",
    "\n",
    "# pick target and drop Y label targets from features\n",
    "y = df[TARGET]\n",
    "X = df.drop(columns=[TARGET, \"days_nom_to_latest_action\"])  # other target saved for later tries at modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2378c",
   "metadata": {},
   "source": [
    "## numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75663fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURES = [\n",
    "    \"actions_count\",\n",
    "    \"age_at_nom_days\",\n",
    "    \"birth_year\", \n",
    "    \"committees_count\",\n",
    "    \"congress_num\", \n",
    "    \"days_into_pres_term\",\n",
    "    \"days_nom_to_deceased\",\n",
    "    \"days_to_next_midterm_election\",\n",
    "    \"days_to_next_pres_election\",\n",
    "    \"death_year\", \n",
    "    \"degree_year\", \n",
    "    \"education_sequence\", \n",
    "    \"fed_service_sequence\", \n",
    "    \"highest_degree_level\",\n",
    "    \"professional_career_sequence\",\n",
    "    \"record_vote_number\",   \n",
    "    \"service_as_chief_judge,_begin\", \n",
    "    \"service_as_chief_judge,_end\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6168585",
   "metadata": {},
   "source": [
    "# boolean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOLEAN_FEATURES = [\n",
    "    \"pres_term_is_latter_term\", \n",
    "    \"statute_authorized_new_seat_bool\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2bbf16",
   "metadata": {},
   "source": [
    "# categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69674cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES  = [\n",
    "    \"aba_rating\", \n",
    "    \"appointing_president\",\n",
    "    \"congress_session\",\n",
    "    \"court_type\",\n",
    "    \"birth_state\",\n",
    "    \"latestaction_is_div_opp_house\",\n",
    "    \"latestaction_is_div_opp_senate\",\n",
    "    \"latestaction_is_fully_div\",\n",
    "    \"latestaction_is_unified\",\n",
    "    \"nomination_vacancy_reason\",\n",
    "    \"nomination_of_or_from_location\",\n",
    "    \"nomination_to_position_title\",\n",
    "    \"nomination_to_court_name\",\n",
    "    \"nominees_0_organization\",\n",
    "    \"nominees_0_state\",\n",
    "    \"nomination_term_years\", # sounds numeric but only few options, including lifetime\n",
    "    \"party_of_appointing_president\",\n",
    "    \"race_or_ethnicity\",\n",
    "    \"received_in_senate_political_era\",\n",
    "    \"school\",\n",
    "    \"seat_level_cong_recategorized\",\n",
    "    \"seat_id_letters_only\",\n",
    "    \"senate_vote_type\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec7c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All features are unique across feature type lists\n",
      "ℹ️ Total unique features: 43\n"
     ]
    }
   ],
   "source": [
    "from nomination_predictor.modeling.train import validate_feature_lists\n",
    "\n",
    "are_features_unique = validate_feature_lists(NUMERIC_FEATURES, BOOLEAN_FEATURES, CATEGORICAL_FEATURES)\n",
    "\n",
    "if not are_features_unique:\n",
    "    raise ValueError(\"Feature lists contain duplicates. Please fix before continuing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa37ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len([col for col in NUMERIC_FEATURES if col not in df.columns]) > 0:\n",
    "    logger.warning(\"The following columns in NUMERIC_FEATURES are absent from the df: {}\".format(\n",
    "        [col for col in NUMERIC_FEATURES if col not in df.columns],\n",
    "    ))\n",
    "if len([col for col in BOOLEAN_FEATURES if col not in df.columns]) > 0:\n",
    "    logger.warning(\"The following columns in BOOLEAN_FEATURES are absent from the df: {}\".format(\n",
    "        [col for col in BOOLEAN_FEATURES if col not in df.columns],\n",
    "    ))\n",
    "if len([col for col in CATEGORICAL_FEATURES if col not in df.columns]) > 0:\n",
    "    logger.warning(\"The following columns in CATEGORICAL_FEATURES are absent from the df: {}\".format(\n",
    "        [col for col in CATEGORICAL_FEATURES if col not in df.columns],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(\"object\").columns.tolist()\n",
    "num_cols = [\n",
    "    c for c in df.select_dtypes(\"number\").columns\n",
    "    if c not in {TARGET}\n",
    "]\n",
    "\n",
    "df_model = df[df[TARGET].notna()].copy()\n",
    "X = df_model[BOOLEAN_FEATURES + CATEGORICAL_FEATURES + NUMERIC_FEATURES]\n",
    "y = df_model[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45705d71",
   "metadata": {},
   "source": [
    "# splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d60c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create composite strata\n",
    "strata = (\n",
    "    df_model[\"seat_level_cong_recategorized\"].astype(str)\n",
    "    + \"__\"\n",
    "    + df_model[\"received_in_senate_political_era\"].astype(str)\n",
    ")\n",
    "\n",
    "# Optionally collapse very-rare strata to 'Other' (prevents ValueError)\n",
    "min_count = 3          # tweak as needed\n",
    "rare_mask = strata.map(strata.value_counts()) < min_count\n",
    "strata = strata.where(~rare_mask, other=\"Other\")\n",
    "\n",
    "# Train–test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=strata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm normally accustomed to naming python constants with all-caps, but my code assist tools are insisting on making these lowercase, so we'll alias them just to appease it\n",
    "numerical_features = NUMERIC_FEATURES\n",
    "categorical_features = CATEGORICAL_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d6351",
   "metadata": {},
   "source": [
    "# Model Selection, Training, and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f304ff9",
   "metadata": {},
   "source": [
    "##  Preprocessing pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d6e32",
   "metadata": {},
   "source": [
    "Given how much data cleaning is(n't) happening so far, it's entirely possible the test data will contain something the training pipeline has never seen in the training data.\n",
    "\n",
    "An example of an error message it threw when this occurred was `ValueError: Found unknown categories ['Syria', 'Russia', 'Trinidad and Tobago', 'Panama'] in column 4 during transform`, presumably because all of those were locations nominees have been appointed to work at or work with.\n",
    "\n",
    "The simplest workaround is to ignore them until/unless enough feature-engineering can be done to re-bin them (e.g. by continent, or job type, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0aecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(\n",
    "            drop='first', \n",
    "            sparse_output=False,\n",
    "            handle_unknown='ignore'  # 🔧 workaround for error described in a markdown cell above\n",
    "        ), categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16561816",
   "metadata": {},
   "source": [
    "## Untuned / naive pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6589d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(\n",
    "        tree_method=\"hist\",      # ✅ Current way\n",
    "        device=\"cuda\",           # ✅ Current way (replaces gpu_id, predictor, etc.)\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a227ec69",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ff3cf",
   "metadata": {},
   "source": [
    "### Choice of metric: MAE\n",
    "\n",
    "Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are both sensitive to outliers, and MSE also doesn't use the same units as our target variable, making it less intuitive.\n",
    "\n",
    "After all our data cleaning, we have few-enough rows of data, with outliers occurring often-enough, that I'm selecting Mean Absolute Error (MAE) as our metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-18 14:35:34.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.predict\u001b[0m:\u001b[36mtrain_and_evaluate_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mTraining XGBoost Baseline on 1424 samples, 43 features\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost Baseline:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost Baseline: 100%|██████████| 1/1 [01:45<00:00, 105.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-18 14:37:19.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.predict\u001b[0m:\u001b[36mtrain_and_evaluate_model\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mTraining completed in 105.15 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions:   0%|          | 0/2 [00:00<?, ?it/s]/home/wsl2ubuntuuser/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/core.py:729: UserWarning: [14:37:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "Making predictions:  50%|█████     | 1/2 [00:00<00:00,  2.04it/s]/home/wsl2ubuntuuser/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [4, 9, 11, 12, 17, 19] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "Making predictions: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate baseline model\n",
    "baseline_results = train_and_evaluate_model(\n",
    "    model=baseline_pipeline,  # ✅ Use the actual pipeline variable name\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_name=\"XGBoost Baseline\",\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb3190f",
   "metadata": {},
   "source": [
    "## Saving with evaluation metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f7bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📊 XGBOOST BASELINE EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "🎯 PERFORMANCE METRICS:\n",
      "  • Training MAE: 0.00 days\n",
      "  • Test MAE:     47.47 days\n",
      "  • Training R²:  1.0000\n",
      "  • Test R²:      0.3480\n",
      "  • Training time: 105.15 seconds\n",
      "\n",
      "===== Mean Absolute Error (MAE): 47.47 =====\n",
      "📊 GOOD: The model's predictions are typically within 60 days of the actual confirmation time.\n",
      "🔍 TAKEAWAY: The model provides valuable insights but has moderate error margins.\n",
      "\n",
      "===== R² Score: 0.3480 =====\n",
      "📊 FAIR: The model explains between 30-50% of the variance in confirmation times.\n",
      "🔍 TAKEAWAY: The model identifies some patterns but misses many important factors.\n",
      "\n",
      "===== Interpretation in Context =====\n",
      "• The average nomination takes 126 days to confirm\n",
      "• With a standard deviation of 85 days\n",
      "• Our model's error (MAE) is 47 days, which is 56% of the standard deviation\n",
      "• This means our model outperforms a baseline model that always predicts the average\n",
      "\n",
      "===== Recommended Next Steps =====\n",
      "1. Tune hyperparameters to optimize model performance\n",
      "2. Explore feature importance to understand key drivers\n",
      "3. Consider ensemble methods to improve predictions\n",
      "\n",
      "🔧 MODEL COMPLEXITY:\n",
      "Model complexity:\n",
      "  • Trees      : 6,000\n",
      "  • Leaf nodes : 0\n",
      "  • ‘Parameters’ (leaf weights) ≈ 0.000000 B\n",
      "\u001b[32m2025-07-18 14:37:20.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36msave_model_with_metadata\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModel saved successfully to /home/wsl2ubuntuuser/nomination_predictor/models/xgboost_baseline_2025-07-18_143720.pkl\u001b[0m\n",
      "\u001b[32m2025-07-18 14:37:20.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomination_predictor.modeling.train\u001b[0m:\u001b[36msave_model_with_metadata\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mModel metadata: xgboost_baseline with 43 features\u001b[0m\n",
      "\n",
      "💾 Model saved to: /home/wsl2ubuntuuser/nomination_predictor/models/xgboost_baseline_2025-07-18_143720.pkl\n"
     ]
    }
   ],
   "source": [
    "baseline_final = evaluate_and_report_model(\n",
    "    results=baseline_results,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_name=\"XGBoost Baseline\",\n",
    "    save_model=True,\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"random_state\": 42,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c68ac4",
   "metadata": {},
   "source": [
    "# Model tuning via randomized hyper-parameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e21ac",
   "metadata": {},
   "source": [
    "## Define hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'model__n_estimators': [100, 500, 1000, 2000, 3000, 6000],\n",
    "    'model__max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'model__subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'model__colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'model__reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'model__reg_lambda': [0, 0.1, 0.5, 1.0],\n",
    "    'model__min_child_weight': [1, 3, 5, 7],\n",
    "    'model__gamma': [0, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439246d",
   "metadata": {},
   "source": [
    "## Tuned pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tuned_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Same fixed preprocessor\n",
    "    ('model', XGBRegressor(\n",
    "        tree_method=\"hist\",      # ✅ Current way\n",
    "        device=\"cuda\",           # ✅ Current way\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd0581",
   "metadata": {},
   "source": [
    "## Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446dc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting GPU-accelerated hyperparameter search...\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 Starting GPU-accelerated hyperparameter search...\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    tuned_pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=1,   # ⚠️ Still important: Set to 1 for GPU\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441de86b",
   "metadata": {},
   "source": [
    "## Search-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753453e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsl2ubuntuuser/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [1, 4, 9, 11, 12, 13, 17, 19, 21] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/home/wsl2ubuntuuser/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [0, 4, 9, 12, 17, 19, 21] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/home/wsl2ubuntuuser/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [1, 4, 9, 10, 11, 12, 14, 17, 19, 21] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/home/wsl2ubuntuuser/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [1, 4, 9, 11, 12, 13, 17, 19, 21] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Best cross-validation score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m-random_search.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MAE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🎯 Best parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/sklearn/pipeline.py:661\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    656\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    657\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    658\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    659\u001b[39m             all_params=params,\n\u001b[32m    660\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/nomination_predictor/lib/python3.12/site-packages/xgboost/core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)\n",
    "print(f\"✅ Best cross-validation score: {-random_search.best_score_:.2f} MAE\")\n",
    "print(f\"🎯 Best parameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f70c6d7",
   "metadata": {},
   "source": [
    "## Evaluating best model found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afa213",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_results = train_and_evaluate_model(\n",
    "    model=random_search.best_estimator_,  # ✅ Use the best estimator from search; search is the object, not pipeline, because did randomized search\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_name=\"XGBoost Tuned\",\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57682a53",
   "metadata": {},
   "source": [
    "## Saving and Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_final = evaluate_and_report_model(\n",
    "    results=tuned_results,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_name=\"XGBoost Tuned\",\n",
    "    save_model=True,\n",
    "    hyperparameters=random_search.best_params_ \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70096f6a",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both models using our comparison function\n",
    "compare_models(\n",
    "    results_list=[baseline_results, tuned_results],\n",
    "    model_names=[\"XGBoost Baseline\", \"XGBoost Tuned\"]\n",
    ")\n",
    "\n",
    "# Display model paths for reference\n",
    "print(f\"\\n📁 SAVED MODELS:\")\n",
    "print(f\"  • Baseline: {baseline_final['model_path']}\")\n",
    "print(f\"  • Tuned:    {tuned_final['model_path']}\")\n",
    "\n",
    "# Show interpretation categories\n",
    "print(f\"\\n🏷️ MODEL QUALITY ASSESSMENT:\")\n",
    "print(f\"  • Baseline: {baseline_final['interpretation']['overall_quality']}\")\n",
    "print(f\"  • Tuned:    {tuned_final['interpretation']['overall_quality']}\")\n",
    "\n",
    "# Feature importance analysis (if desired)\n",
    "best_model = tuned_final['model']\n",
    "if hasattr(best_model, 'feature_importances_') or hasattr(best_model[-1], 'feature_importances_'):\n",
    "    print(f\"\\n🔍 TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = best_model[:-1].get_feature_names_out()\n",
    "    \n",
    "    # Get feature importances\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        importances = best_model.feature_importances_\n",
    "    else:\n",
    "        importances = best_model[-1].feature_importances_\n",
    "    \n",
    "    # Create feature importance DataFrame\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Display top 10\n",
    "    for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows()):\n",
    "        print(f\"  {i+1:2d}. {row['feature']:<30} {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5324e6b",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d085e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs Predicted (Baseline)\n",
    "axes[0, 0].scatter(y_test, baseline_results['predictions']['y_test_pred'], alpha=0.6)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual Days')\n",
    "axes[0, 0].set_ylabel('Predicted Days')\n",
    "axes[0, 0].set_title(f'Baseline Model\\nMAE: {baseline_results[\"metrics\"][\"test_mae\"]:.2f} days')\n",
    "\n",
    "# 2. Actual vs Predicted (Tuned)\n",
    "axes[0, 1].scatter(y_test, tuned_results['predictions']['y_test_pred'], alpha=0.6)\n",
    "axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 1].set_xlabel('Actual Days')\n",
    "axes[0, 1].set_ylabel('Predicted Days')\n",
    "axes[0, 1].set_title(f'Tuned Model\\nMAE: {tuned_results[\"metrics\"][\"test_mae\"]:.2f} days')\n",
    "\n",
    "# 3. Residuals (Baseline)\n",
    "baseline_residuals = y_test - baseline_results['predictions']['y_test_pred']\n",
    "axes[1, 0].scatter(baseline_results['predictions']['y_test_pred'], baseline_residuals, alpha=0.6)\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 0].set_xlabel('Predicted Days')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].set_title('Baseline Residuals')\n",
    "\n",
    "# 4. Residuals (Tuned)\n",
    "tuned_residuals = y_test - tuned_results['predictions']['y_test_pred']\n",
    "axes[1, 1].scatter(tuned_results['predictions']['y_test_pred'], tuned_residuals, alpha=0.6)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 1].set_xlabel('Predicted Days')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('Tuned Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomination_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
